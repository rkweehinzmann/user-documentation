{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to SciCat Documentation","text":"<p>Find SciCat USERS Guide or SciCat Operator's Guide. Developers can read along the <code>READMEs</code> in github of the projects page and in both guides as well.</p>"},{"location":"about/","title":"About the team - who are we?","text":"<p>SciCat has been initially developed at PSI but is now in production use across many other European and transatlantic countries. The core institutes are still PSI and ESS, but invaluable contribution comes from other labs, see SciCat Team for up-to-date details.</p>"},{"location":"about/#about-scicat-version","title":"About SciCat version","text":"<p>Here is where you find the frontend version.</p>"},{"location":"about/operatorHowTos/","title":"Where is the version of SciCat Frontend?","text":"<p>Version information under <code>user</code> </p>"},{"location":"backendconfig/","title":"Central Configuration of Backend: <code>.env</code>","text":"<p>The configuration file <code>.env</code> allows the systems administrator to configure connected services, like authentication services and message queues, and also switching on/off almost all available features and is read by the backend at runtime.</p> <p>There are currently many configurable additions to SciCat which makes it very flexible these are:</p> <ul> <li>OIDC for identification</li> <li>LDAP for authentication</li> <li>Elastic Search</li> <li>SMTP for sending emails to notify users of SciCat jobs</li> <li>AMQP to provide a message queue for the jobs</li> </ul>"},{"location":"backendconfig/#environment-variables","title":"Environment Variables","text":"<p>All environment variables can be used in the <code>.env</code> filee. The current source code contains an example .env file, named .env.example, listing all (79) environment variables available to configure the backend. They can be found here and define</p> <ul> <li>How SciCat handles access rights and connects to other services e.g. to identity providers - such as LDAP or OIDC for authentication.</li> <li>How to configure DOIs.</li> <li>How to configure elasitc search (ES)</li> <li>How to configure jobs</li> </ul> <p>The list is compiled according to the configuration class defined in src/config/configuration.ts.</p> <ul> <li> <p>ADMIN_GROUPS:   list of groups that have admin priviliges default: \"\" format: comma separated list of strings. Leading and trailing spaces are trimmed.  </p> </li> <li> <p>DELETE_GROUPS:   list of groups that are allowed to delete content default: \"\" format: comma separated list of strings. Leading and trailing spaces are trimmed.  </p> </li> <li> <p>CREATE_DATASET_GROUPS:   list of non admin groups that are allowed to create datasets without pid. The pid is assigned by the system. If set to \"#all\", all users can create a dataset belonging to any of the groups they belong to.   default: \"#all\" format: comma separated list of strings. Leading and trailing spaces are trimmed.  </p> </li> <li> <p>CREATE_DATASET_WITH_PID_GROUPS:   list of non admin groups that are allowed to create datasets with explicit pid. If set to \"#all\", all users can create a dataset belonging to any of the groups they belong to and with esplicit pid.   If the pid verification is enabled, pid will be validated agains the specification passed. default: \"\" format: comma separated list of strings. Leading and trailing spaces are trimmed.  </p> </li> <li> <p>CREATE_DATASET_PRIVILEGED_GROUPS:   list of non admin groups that are allowed to create datasets for groups they do not belong to. If set to \"#all\", all users can create a dataset belonging to any group with explicit pid.   If the pid verification is enabled, pid will be validated agains the specification passed. default: \"\" format: comma separated list of strings. Leading and trailing spaces are trimmed.  </p> </li> <li> <p>PROPOSAL_GROUPS:   list of non admin groups that are allowed to create and update proposals for groups they do not belong to. If set to \"#all\", all users can create a dataset belonging to any group with explicit pid. default: \"\" format: comma separated list of strings. Leading and trailing spaces are trimmed  </p> </li> <li> <p>SAMPLE_GROUPS:   list of non admin groups that are allowed to create and update samples for the groups they belong to. If set to \"#all\", all users can create a dataset belonging to their group. default: \"\" format: comma separated list of strings. Leading and trailing spaces are trimmed  </p> </li> <li> <p>SAMPLE_PRIVILEGED_GROUPS:   list of non admin groups that are allowed to create samples for any groups, but can only update samples belonging to groups they belong to.   default: \"\" format: comma separated list of strings. Leading and trailing spaces are trimmed  </p> </li> <li> <p>ACCESS_GROUPS_STATIC_VALUES:   List of groups assigned by default to all users. Used in the vanilla implementation for easy configuration.   If you do not want or need to assign any default group, it should be set to empty string \"\".   Default value: \"\" format: Comman separated list of strings. Leading and trailing spaces are trimmed example: \"group1,group2,group3,...\"  </p> </li> <li> <p>ACCESS_GROUP_SERVICE_TOKEN:   Access token needed to access the API specified in ACCESS_GROUP_SERVICE_API_URL, used to retrieve access groups from a third party system.   _format*: string </p> </li> <li> <p>ACCESS_GROUP_SERVICE_API_URL:   Well formed url of the service API used to provide access groups. Only one value is allowed. format: string example: \"https://my.access.group/service/api/url\"</p> </li> <li> <p>DOI_PREFIX:   The facility DOI prefix, with trailing slash. default: \"\" format: string  </p> </li> <li> <p>EXPRESS_SESSION_SECRET:   Secret used to set up express session. default: \"\" format: string  </p> </li> <li> <p>LOGOUT_URL:   URL specified upon successful logout. It is returned in the json object for the frontend, or third party UI, to be used locally. default: \"\" format: string  </p> </li> <li> <p>HTTP_MAX_REDIRECTS:   Max number of redirects for http requests. default: 5 format: integer  </p> </li> <li> <p>HTTP_TIMEOUT:   Timeout from http requests in ms. default: 5000 format: integer</p> </li> <li> <p>JWT_SECRET:   The secret used to create any JWT token, used for authorization. default: \"\" format: string  </p> </li> <li> <p>JWT_EXPIRES_IN:   Expiration time of any JWT token in seconds. default: 3600 (s) format: integer  </p> </li> <li> <p>JWT_NEVER_EXPIRES:   Length of time that the never expiring jwt token will last. default: 100y format: string as in number of years  </p> </li> <li> <p>LDAP_URL:   Full URI (including port) of your local LDAP server, if this is your selected authentication method. default: No default example: ldaps://ldap.server.com:636/  format: string  </p> </li> <li> <p>LDAP_BIND_DN:   Bind DN to access information on your LDAP server. default: No default format: string  </p> </li> <li> <p>LDAP_BIND_CREDENTIALS:   Credentials associated with your bind DN to acccess your LDAP server. default: No default format: string  </p> </li> <li> <p>LDAP_SEARCH_BASE:   Search base for your LDAP server. default: No default  format: string  </p> </li> <li> <p>LDAP_SEARCH_FILTER:   Search filter for you LDAP server. default: No default format: string  example: \"(LDAPUsername={{username}})\"  </p> </li> <li> <p>LDAP_MODE:   type of ldap server we are communicating with NEEDS TO BE UPDATED. Not sure which other values are accepted default: ad format: string acceptable values: ad  </p> </li> <li> <p>LDAP_EXTERNAL_ID:   LDAP matching field that provides the external id default: sAMAccountName format: string  </p> </li> <li> <p>LDAP_USERNAME:   LDAP field providing the username default: displayName format: string  </p> </li> <li> <p>OIDC_ISSUER:   Full URL of your OIDC identity provider default: No default format: string example: \"https://identity.your.facility/your/realm\"  </p> </li> <li> <p>OIDC_CLIENT_ID:   Client id used to convert OIDC code to OIDC token. This is assigned in the OIDC service when the token is generated default: No default format: string example: \"scicat\"  </p> </li> <li> <p>OIDC_CLIENT_SECRET:    Token used to convert OIDC code to OIDC token. This is assigned in the OIDC service when the token is generated example: \"90f1268...\"  </p> </li> <li> <p>OIDC_CALLBACK_URL:   URL of the endpoint that is called when the authentication has been executed with the OIDC service.  default: No default  format: string   example: \"http://localhost:3000/api/v3/oidc/callback\"  </p> </li> <li> <p>OIDC_SCOPE:   Information returned by the OIDC service together with token default: No default format: string  example: \"openid profile email\"  </p> </li> <li> <p>OIDC_SUCCESS_URL:   Frontend URL that the user is directed to after a successful authentication. It must be a valid frontend URL. default: No default format: string example: \"http://localhost:3000/Datasets\"  </p> </li> <li> <p>OIDC_ACCESS_GROUPS:   field used to retrieve access groups from the OIDC service. It is not used in the vanilla implementation. default: No default format: string example: \"access_groups\"  </p> </li> <li> <p>OIDC_ACCESS_GROUPS_PROPERTY:   name of the OIDC property used to retrieve the users groups from OIDC. default: none format: string  </p> </li> <li> <p>OIDC_AUTO_LOGOUT:   if enabled, when login out from SciCat, we logout from OIDC also. default: false format: boolean  </p> </li> <li> <p>OIDC_RETURN_URL:   URL the user is redirected after a successful logout default: none format: string  </p> </li> <li> <p>LOGBOOK_ENABLED:   Flag to enable/disable the Logbook endpoints.   accept values: \"yes\", \"no\" default: no  format: string  </p> </li> <li> <p>LOGBOOK_BASE_URL:   The base URL to the SciChat wrapper API. Only required if Logbook is enabled. default: \"http://localhost:3030/scichatapi\" format: string  </p> </li> <li> <p>LOGBOOK_USERNAME:   The username used to authenticate to the SciChat wrapper API. Only required if Logbook is enabled. default: No default format: string  </p> </li> <li> <p>LOGBOOK_PASSWORD:   The password used to authenticate to the SciChat wrapper API. Only required if Logbook is enabled. default: No default format: string  </p> </li> <li> <p>METADATA_KEYS_RETURN_LIMIT:   The maximum number of keys returned by the <code>/Datasets/metadataKeys</code> endpoint. default: No default format: integer  </p> </li> <li> <p>METADATA_PARENT_INSTANCES_RETURN_LIMIT:   The maximum number of Datasets used to extract metadata keys in the <code>/Datasets/metadataKeys</code> endpoint. default: No default format: integer  </p> </li> <li> <p>MONGODB_URI:   The URI for your MongoDB instance. default: No default format: string \"mongodb://:@:27017/\"   <li> <p>OAI_PROVIDER_ROUTE:   URI to OAI provider, which is used in the <code>/publisheddata/:id/resync</code> endpoint. default: no default format: string  </p> </li> <li> <p>PID_PREFIX:   The facility PID prefix, with trailing slash. default: no default format: string  </p> </li> <li> <p>PUBLIC_URL_PREFIX:   The base URL to the facility Landing Page. default: No default format: string example: \"https://doi.ess.eu/detail/\"  </p> </li> <li> <p>PORT:   The port on which the backend listen on. default: 3000 format: integer  </p> </li> <li> <p>RABBITMQ_ENABLED:   Flag to enable/disable RabbitMQ consumer.   accepted values: \"yes\", \"no\" deprecated. Will be removed in future releases. default: no format: string  </p> </li> <li> <p>RABBITMQ_HOSTNAME:   The hostname of the RabbitMQ message broker. Only required if RabbitMQ is enabled. deprecated. Will be removed in future releases. default: no default default: string  </p> </li> <li> <p>RABBITMQ_USERNAME:   The username used to authenticate to the RabbitMQ message broker. Only required if RabbitMQ is enabled. deprecated. Will be removed in future releases. default: no default format: string  </p> </li> <li> <p>RABBITMQ_PASSWORD:   The password used to authenticate to the RabbitMQ message broker. Only required if RabbitMQ is   enabled. deprecated. Will be removed in future releases. default: no default format: string  </p> </li> <li> <p>REGISTER_DOI_URI:   URI to the organization that registers the facilities DOIs. default: no default format: string example: \"https://mds.test.datacite.org/doi\"  </p> </li> <li> <p>REGISTER_METADATA_URI:   URI to the organization that registers the facilities published data metadata. default: no default format: string example: =\"https://mds.test.datacite.org/metadata\"  </p> </li> <li> <p>DOI_USERNAME:   Username used to authenticate on the DOI site default: no default format: string  </p> </li> <li> <p>DOI_PASSWORD:   Password used to authenticate on the DOI site default: no default format: string  </p> </li> <li> <p>SITE:   The name of your site. default: no default format: string  </p> </li> <li> <p>SMTP_HOST:   Host of SMTP server. deprecated. Will be removed in future releases. default: no default format: string  </p> </li> <li> <p>SMTP_MESSAGE_FROM:   Email address that emails should be sent from. deprecated. Will be removed in future releases. default: no default format: string, email  </p> </li> <li> <p>SMTP_PORT:   Port of SMTP server. deprecated. Will be removed in future releases. default: no default format: string  </p> </li> <li> <p>SMTP_SECURE:   Secure of SMTP server. deprecated. Will be removed in future releases. default: no default format: string  </p> </li> <li> <p>POLICY_PUBLICATION_SHIFT:   Number of years that needs to elapse before the dataset is made publicly acceessible default: 3 format: integer  </p> </li> <li> <p>POLICY_RETENTION_SHIFT:   Number of years that the datasets are kept online before are archived or deleted. A negative value means that they are never archived/deleted default: -1 format: integer  </p> </li> <li> <p>ELASTICSEARCH_ENABLED:   Flag to enable/disable the ElasticSearch service   accept values: \"yes\", \"no\" default: no default format: string  </p> </li> <li> <p>ES_HOST:   The base URL to the Elasticsearch cluster. Use <code>http</code> if xpack.security is disabled default: no default format: string  example: \"https://localhost:9200\" or \"http://localhost:9200\"  </p> </li> <li> <p>MONGODB_COLLECTION:   Collection name to be mapped into specified Elasticsearch index default: no default format: string  </p> </li> <li> <p>ES_MAX_RESULT:    Maximum records can be indexed into Elasticsearch. default: 10000 format: number  </p> </li> <li> <p>ES_FIELDS_LIMIT:    The total number of fields in an index. default: 1000 format: number  </p> </li> <li> <p>ES_INDEX:   The total number of fields in an index. default: no default format: string  </p> </li> <li> <p>ES_REFRESH:   The total number of fields in an index.   accept values: true, false, \"wait_for\" default: false format: boolean or string  </p> </li> <li> <p>ES_USERNAME:   Elasticsearch cluster username. default: no default, optional. format: string  </p> </li> <li> <p>ELASTIC_PASSWORD:    Elasticsearch cluster password. default: no default. format: string  </p> </li>"},{"location":"backendconfig/#environment-variables-as-now","title":"Environment Variables as now","text":"<pre><code>ACCESS_GROUP_SERVICE_API_URL=\"\"\nACCESS_GROUP_SERVICE_TOKEN=\"\"\nDOI_PREFIX=\"&lt;DOI_PREFIX&gt;\"\nEXPRESS_SESSION_SECRET=\"&lt;EXPRESS_SESSION_SECRET&gt;\"\nHTTP_MAX_REDIRECTS=5\nHTTP_TIMEOUT=5000\nJWT_SECRET=&lt;JWT_SECRET&gt;\nJWT_EXPIRES_IN=3600\nLDAP_URL=\"ldaps://ldap.server.com:636/\"\nLDAP_BIND_DN=\"&lt;USERNAME&gt;@server.com\"\nLDAP_BIND_CREDENTIALS=&lt;PASSWORD&gt;\nLDAP_SEARCH_BASE=&lt;SEARCH_BASE&gt;\nLDAP_SEARCH_FILTER=\"(LDAPUsername={{username}})\"\nLOGBOOK_ENABLED=\"no\"\nLOGBOOK_BASE_URL=\"http://localhost:3030/scichatapi\"\n\nMETADATA_KEYS_RETURN_LIMIT=100\nMETADATA_PARENT_INSTANCES_RETURN_LIMIT=100\nMONGODB_URI=\"mongodb://&lt;USERNAME&gt;:&lt;PASSWORD&gt;@&lt;HOST&gt;:27017/&lt;DB_NAME&gt;\"\nOAI_PROVIDER_ROUTE=\"&lt;OAI_PROVIDER_ROUTE&gt;\"\nPID_PREFIX=\"&lt;PID_PREFIX&gt;\"\nPUBLIC_URL_PREFIX=\"https://doi.esss.se/detail/\"\nPORT=3000\nRABBITMQ_ENABLED=&lt;\"yes\"|\"no\"&gt;\nRABBITMQ_HOSTNAME=\"localhost\"\nRABBITMQ_USERNAME=\"rabbitmq\"\nRABBITMQ_PASSWORD=\"rabbitmq\"\nREGISTER_DOI_URI=\"https://mds.test.datacite.org/doi\"\nREGISTER_METADATA_URI=\"https://mds.test.datacite.org/metadata\"\nDOI_USERNAME=\"username\"\nDOI_PASSWORD=\"password\"\nSITE=&lt;SITE&gt;\nEMAIL_TYPE=&lt;\"smtp\"|\"ms365\"&gt;\nEMAIL_FROM=&lt;MESSAGE_FROM&gt;\nSMTP_HOST=&lt;SMTP_HOST&gt;\nSMTP_PORT=&lt;SMTP_PORT&gt;\nSMTP_SECURE=&lt;\"yes\"|\"no\"&gt;\nMS365_TENANT_ID=&lt;tenantId&gt;\nMS365_CLIENT_ID=&lt;clientId&gt;\nMS365_CLIENT_SECRET=&lt;clientSecret&gt;\n\nDATASET_CREATION_VALIDATION_ENABLED=true\nDATASET_CREATION_VALIDATION_REGEX=\"^[0-9A-F]{8}-[0-9A-F]{4}-4[0-9A-F]{3}-[89AB][0-9A-F]{3}-[0-9A-F]{12}$\"\n\nADMIN_GROUPS=\"\"\nDELETE_GROUPS=\"\"\nCREATE_DATASET_GROUPS=\"all\"\nCREATE_DATASET_WITH_PID_GROUPS=\"\"\nCREATE_DATASET_PRIVILEGED_GROUPS=\"\"\nCREATE_JOB_GROUPS=\"\"\nUPDATE_JOB_GROUPS=\"\"\nSAMPLE_PRIVILEGED_GROUPS=\"sampleingestor\"\nSAMPLE_GROUPS=\"group1\"\nPROPOSAL_GROUPS=\"\"\n\nACCESS_GROUPS_GRAPHQL_ENABLED=true\nACCESS_GROUP_SERVICE_TOKEN=\"\"\nACCESS_GROUP_SERVICE_API_URL=\"\"\nACCESS_GROUP_SERVICE_HANDLER=\"\"\nACCESS_GROUPS_STATIC_ENABLED=true\nACCESS_GROUPS_OIDCPAYLOAD_ENABLED=true\n\nOIDC_USERINFO_MAPPING_FIELD_USERNAME=\"iss, sub\"\nOIDC_USERINFO_MAPPING_FIELD_DISPLAYNAME=\"preferred_username\"\nOIDC_USERINFO_MAPPING_FIELD_EMAIL=\"email\"\nOIDC_USERINFO_MAPPING_FIELD_GROUP=\"groups\"\nOIDC_USERQUERY_OPERATOR=&lt;\"or\"|\"and\"&gt;\nOIDC_USERQUERY_FILTER=\"username:username, email:email\"\n\nELASTICSEARCH_ENABLED=&lt;\"yes\"|\"no\"&gt;\nSTACK_VERSION=\"8.8.2\"\nCLUSTER_NAME=\"es-cluster\"\nMEM_LIMIT=\"4G\"\nMONGODB_COLLECTION=\"Dataset\"\nES_MAX_RESULT=100000\nES_FIELDS_LIMIT=400000\nES_INDEX=\"dataset\"\nES_PORT=9200\nES_HOST=\"https://localhost:9200\"\nES_USERNAME=\"elastic\"\nES_PASSWORD=\"duo-password\"\nES_REFRESH=&lt;\"wait_for\"|\"false\"&gt;\n\nLOGGERS_CONFIG_FILE=\"loggers.json\"\nDATASET_TYPES_FILE=\"datasetTypes.json\"\nPROPOSAL_TYPES_FILE=\"proposalTypes.json\"\n</code></pre>"},{"location":"backendconfig/#how-to-configure-to-connect-the-backend-to-other-services","title":"How to configure to connect the backend to other services","text":"<p>In scicatlive you find documentation on how to integrate your SciCat system with services providing identities, (e.g. KeyCloak) and authentication (OpenLDAP).</p>"},{"location":"backendconfig/#how-to-configure-doi-minting","title":"How to configure DOI minting","text":"<p>In SciCat one can publish selected datasets that triggers a DOI minting process. Find here a short introduction on SciCats Published Data class. Instructions how to configure this DOI minting service and in addition make datasets publicly via APIs follow this Link.</p>"},{"location":"backendconfig/#more-advanced-options","title":"More advanced options","text":"<p>If you are compiling the application from source, you can edit the file src/config/configuration.ts with the correct values for your infrastructure. This option is still undocumented, although it is our intention to provide a detailed how-to guide as soon as we can.</p>"},{"location":"backendconfig/dois/","title":"DOI minting in SciCat - How to set up publication of datasets","text":""},{"location":"backendconfig/dois/#introduction","title":"Introduction","text":"<p>User introduction can be found here.</p>"},{"location":"backendconfig/dois/#variables-to-configure","title":"Variables to configure","text":"<p>We repeat here the relevant parts from the <code>.env</code>-file that essentially give handle to the admin-user:</p> <ul> <li>REGISTER_DOI_URI=\"https://mds.test.datacite.org/doi\"</li> <li>REGISTER_METADATA_URI=\"https://mds.test.datacite.org/metadata\"</li> <li>DOI_USERNAME=\"username\"</li> <li>DOI_PASSWORD=\"password\"</li> </ul> <p>The up to now main landing page server as separate frontend client will become redundant: other than datasets can be chosen as entry points to benefit from the nice search on datasets, one can simply use also the publishedData main page as entry point for displaying all externaly accessible DOIs.</p>"},{"location":"backendconfig/dois/#full-potential-with-scicats-apis","title":"Full potential with SciCat's APIs","text":"<p>The respective endpoints can be viewed from swagger and are</p> <p>List of API endpoints one can access: </p>"},{"location":"backendconfig/dois/#endpoints","title":"Endpoints","text":""},{"location":"backendconfig/dois/#post","title":"post","text":"<p>Main one is to the post object:</p> <p></p> <p>Others are</p>"},{"location":"backendconfig/dois/#count","title":"count","text":""},{"location":"backendconfig/dois/#register","title":"register","text":""},{"location":"backendconfig/dois/#form-populate","title":"form populate","text":""},{"location":"backendconfig/dois/#resync","title":"resync","text":""},{"location":"backendconfig/authorization/","title":"Authorization Model","text":""},{"location":"backendconfig/authorization/#general","title":"General","text":"<p>For how authorization is handled in SciCat, see general description.</p> <p>Developers information, see github.</p>"},{"location":"backendconfig/authorization/#authorization-datasets","title":"Authorization Datasets","text":"<p>Summary of how authorization for Datasets are handeld better visible displayed.</p> <p>Developers information, see github.</p>"},{"location":"backendconfig/authorization/#authorization-origdatablocks","title":"Authorization OrigDatablocks","text":"<p>Summary of how authorization for OrigDatablocks are handeld better visible displayed.</p> <p>Developers information, see github.</p>"},{"location":"backendconfig/authorization/#authorization-jobs","title":"Authorization Jobs","text":"<p>Summary of how authorization for OrigDatablocks are handeld better visible displayed.</p> <p>Developers information, see github.</p>"},{"location":"backendconfig/authorization/#authorization-users","title":"Authorization Users","text":"<p>Summary of how authorization for Users are handeld better visible displayed.</p> <p>Developers information, see github.</p>"},{"location":"backendconfig/authorization/#authorization-proposals","title":"Authorization Proposals","text":"<p>Summary of how authorization for proposals are handeld better visible displayed.</p> <p>Developers information, see github.</p>"},{"location":"backendconfig/authorization/#authorization-intruments","title":"Authorization Intruments","text":"<p>Summary of how authorization for instruments are handeld better visible displayed.</p> <p>Developers information, see github.</p>"},{"location":"backendconfig/authorization/authorization/","title":"Authorization","text":""},{"location":"backendconfig/authorization/authorization/#permission-settings-or-who-can-do-what","title":"Permission settings or who can do what?","text":"<p>SciCat backend v4.x relies on CASL to manage permissions. The default vanilla installation of the backend is configured with the permissions described and linked below.  To avoid confusion and clarify the terminology used below, the term User indicates a normal authenticated user with no elevated permissions, while Admin indicates any user who belongs to a group that it is listed in the environmental variable ADMIN_GROUPS. By default ADMIN_GROUPS is set to groups: admin, ingestor, archivemanager. Special case is for deleting items in SciCat. Users with groups listed in DELETE_GROUPS, are allowed to perform delete. Default value is archivemanager.</p> <p>IMPORTANT In v3.x, permissions were managed through roles. In v4.x, roles are not used, and they are converted to user groups.</p> <p>In the vanilla installation, the default functional accounts are assigned to groups as follow: - user: admin   group: admin  </p> <ul> <li> <p>user: ingestor   group: ingestor  </p> </li> <li> <p>user: archiveManager   group: archivemanager</p> </li> </ul> <p>This allow for the flexibility required by many installations in different facilities with different needs.  </p>"},{"location":"backendconfig/authorization/authorization/#group-lists-available-in-vanilla-configuration","title":"Group Lists available in Vanilla Configuration","text":"<p>The permissions in the vanilla installation provides a set of user groups which acquires specific set of permissions. In order to assign a set of permissions to a specific group of user, add such group to the correct list indicated below.</p> Configuration Group List Description CASL ability actions authenticated users Authenticated users can view/access all datasets that belong to one of the groups they belong to DatasetReadOwn Users can view attachments for datasets belonging to one of their group DatasetAttachmentReadOwn Users are allowed to view origdatablocks for datasets belonging to one of their group DatasetOrigdatablockReadOwn Users are allowed to view datablocks for datasets belonging to one of their group DatasetDatablockReadOwn Users can view the logbook of the datasets that belong to one of their group DatasetLogbookReadOwn CREATE_DATASET_GROUPS Users of the listed groups can create and modify datasets for any of the groups they belong to. At creation time, the system assignes a pid to the new datasets. If the user assigns one, the system will ignore it. DatasetCreateOwn , DatasetReadOwn , DatasetUpdateOwn Users are allowed to perform all operations on attachments for datasets belonging to one of their group DatasetAttachmentCreateOwn , DatasetAttachmentReadOwn , DatasetAtatchementUpdateOwn , DatasetAttachmentDeleteOwn Users are allowed to create and update origdatablocks for datasets belonging to one of their group DatasetOrigdatablockCreateOwn , DatasetOrigdatablockReadOwn , DatasetOrigdatablockUpdateOwn Users are allowed to create and update datablocks for datasets belonging to one of their group DatasetDatablockCreateOwn , DatasetDatablockReadOwn , DatasetDatablockUpdateOwn Users can view the logbook of the datasets that belong to one of their group DatasetLogbookReadOwn CREATE_DATASET_WITH_PID_GROUPS Users of the listed groups can create and modify datasets for any of the groups they belong to. They are allowed to specify the dataset pid. If they decided not to specify a pid, the system will assign one. DatasetCreateOwn , DatasetReadOwn , DatasetUpdateOwn Users are allowed to perform all operations on attachments for datasets belonging to one of their group DatasetAttachmentCreateOwn , DatasetAttachmentReadOwn , DatasetAtatchementUpdateOwn , DatasetAttachmentDeleteOwn Users are allowed to create and update origdatablocks for datasets belonging to one of their group DatasetOrigdatablockCreateOwn , DatasetOrigdatablockReadOwn , DatasetOrigdatablockUpdateOwn Users are allowed to create and update datablocks for datasets belonging to one of their group DatasetDatablockCreateOwn , DatasetDatablockReadOwn , DatasetDatablockUpdateOwn Users can view the logbook of the datasets that belong to one of their group DatasetLogbookReadOwn CREATE_DATASET_PRIVILEGED_GROUPS Users of the listed groups can create datasets for any group, but can only modify datasets belong to one of the group they belong to. They are allowed to specify pids for new datasets. This settings are suggested for ingestion functional accounts DatasetCreateAll , DatasetReadOwn , DatasetUpdateOwn Users are allowed to perform all operations on attachments for datasets belonging to one of their group DatasetAttachmentCreateOwn , DatasetAttachmentReadOwn , DatasetAtatchementUpdateOwn , DatasetAttachmentDeleteOwn Users are allowed to create origdatablocks for any datasets, but can only update them for datasets belonging to one of their group DatasetOrigdatablockCreateAny , DatasetOrigdatablockReadOwn , DatasetOrigdatablockUpdateOwn Users are allowed to create and update datablocks for datasets belonging to one of their group DatasetDatablockCreateOwn , DatasetDatablockReadOwn , DatasetDatablockUpdateOwn Users can view the logbook of the datasets that belong to one of their group DatasetLogbookReadOwn ADMIN_GROUPS Users of the listed groups can create and modify datasets belonging to any group. They are allowed to specify the dataset's pid at creation time DatasetCreateAny , DatasetReadAny , DatasetUpdateAny Users are allowed to perform all operations on attachments for any datasets DatasetAttachmentCreateAny , DatasetAttachmentReadAny , DatasetAtatchementUpdateAny , DatasetAttachmentDeleteAny Users are allowed to perform all operations on origdatablocks for any datasets, except delete DatasetOrigdatablockCreateAny , DatasetOrigdatablockReadAny , DatasetOrigdatablockUpdateAny Users are allowed to perform all operations on datablocks for any datasets, except delete DatasetDatablockCreateAny , DatasetDatablockReadAny , DatasetDatablockUpdateAny Users can view logbook for any datasets DatasetLogbookReadAny DELETE_GROUPS Users whose group is listed here are allowed to delete datasets, origdatablock or datablock DatasetDeleteAny , DatasetOrigdatablockDeleteAny , DatasetDatablockDeleteAny"},{"location":"backendconfig/authorization/authorization/#subsystems","title":"Subsystems","text":"<ul> <li>Datasets</li> <li>OrigDatablocks</li> <li>Jobs</li> <li>Users</li> </ul> <p>N.B.: we know that many subsystems are still missing. We are working on reviewing the authorization model for each one of them and producing the relative documentation. We welcome any contribution.</p>"},{"location":"backendconfig/authorization/authorization_datasets/","title":"Datasets Authoorization","text":""},{"location":"backendconfig/authorization/authorization_datasets/#casl-ability-actions","title":"CASL ability actions","text":"<p>This is the list of the permissions methods available for datasets and all their endpoints and more fine-grained instance authorization. </p>"},{"location":"backendconfig/authorization/authorization_datasets/#endpoint-authorization","title":"Endpoint authorization","text":"<ol> <li>DatasetCreate</li> <li>DatasetRead</li> <li>DatasetUpdate</li> <li>DatasetDelete</li> <li>DatasetAttachmentCreate</li> <li>DatasetAttachmentRead</li> <li>DatasetAttachmentUpdate</li> <li>DatasetAttachmentDelete</li> <li>DatasetOrigdatablockCreate</li> <li>DatasetOrigdatablockRead</li> <li>DatasetOrigdatablockUpdate</li> <li>DatasetOrigdatablockDelete</li> <li>DatasetDatablockCreate</li> <li>DatasetDatablockRead</li> <li>DatasetDatablockUpdate</li> <li>DatasetDatablockDelete</li> <li>DatasetLogbookRead</li> </ol>"},{"location":"backendconfig/authorization/authorization_datasets/#instance-authorization","title":"Instance authorization","text":"<ol> <li>DatasetCreateOwnerNoPid</li> <li>DatasetCreateOwnerWithPid</li> <li>DatasetCreateAny</li> <li>DatasetReadManyPublic</li> <li>DatasetReadManyAccess</li> <li>DatasetReadManyOwner</li> <li>DatasetReadOnePublic</li> <li>DatasetReadOneAccess</li> <li>DatasetReadOneOwner</li> <li>DatasetReadAny</li> <li>DatasetUpdateOwner</li> <li>DatasetUpdateAny</li> <li>DetasetDeleteOwner</li> <li>DatasetDeleteAny</li> <li>DatasetAttachmentCreateOwner</li> <li>DatasetAttachmentCreateAny</li> <li>DatasetAttachmentReadPublic</li> <li>DatasetAttachmentReadAccess</li> <li>DatasetAttachmentReadOwner</li> <li>DatasetAttachmentReadAny</li> <li>DatasetAtatchementUpdateOwner</li> <li>DatasetAtatchementUpdateAny</li> <li>DatasetAttachmentDeleteOwner</li> <li>DatasetAttachmentDeleteAny</li> <li>DatasetOrigdatablockCreateOwner</li> <li>DatasetOrigdatablockCreateAny</li> <li>DatasetOrigdatablockReadPublic</li> <li>DatasetOrigdatablockReadAccess</li> <li>DatasetOrigdatablockReadOwner</li> <li>DatasetOrigdatablockReadAny</li> <li>DatasetOrigdatablockUpdateOwner</li> <li>DatasetOrigdatablockUpdateAny</li> <li>DatasetOrigdatablockDeleteAny</li> <li>DatasetDatablockCreateOwner</li> <li>DatasetDatablockCreateAny</li> <li>DatasetDatablockReadPublic</li> <li>DatasetDatablockReadAccess</li> <li>DatasetDatablockReadOwner</li> <li>DatasetDatablockReadAny</li> <li>DatasetDatablockUpdateOwner</li> <li>DatasetDatablockUpdateAny</li> <li>DatasetDatablockDeleteOwner</li> <li>DatasetDatablockDeleteAny</li> <li>DatasetLogbookReadOwner</li> <li>DatasetLogbookReadAny</li> </ol>"},{"location":"backendconfig/authorization/authorization_datasets/#implementation","title":"Implementation","text":"<p>How the different level of authorization translates in data condition applied byt he backend.</p> <ul> <li>Public</li> <li><code>isPublished = true</code></li> <li>Access\u00a0(condition ar applied in logical or)</li> <li><code>isPublished = true</code></li> <li><code>ownerGroup</code> is one of the groups that the user belongs</li> <li><code>accessGroups</code> are one of the groups that the user belongs</li> <li><code>sharedWith</code> contains the user's email</li> <li>Owner </li> <li><code>ownerGroup</code> is one of the groups that the user belongs</li> <li>Any</li> <li>User can perform the action to any dataset</li> </ul>"},{"location":"backendconfig/authorization/authorization_datasets/#priority","title":"Priority","text":"<pre><code>    DatasetCreate--&gt;DatasetCreateOwnerNoPid;\n    DatasetCreateOwnerNoPid--&gt;DatasetCreateOwnerWithPid;\n    DatasetCreateOwnerWithPid--&gt;DatasetCreateAny;\n</code></pre> <pre><code>    DatasetRead--&gt;DatasetReadManyPublic;\n    DatasetReadManyPublic--&gt;DatasetReadManyAccess;\n    DatasetReadManyAccess--&gt;DatasetReadManyOwner;\n    DatasetReadManyOwner--&gt;DatasetReadAny;\n    DatasetRead--&gt;DatasetReadOnePublic;\n    DatasetReadOnePublic--&gt;DatasetReadOneAccess;\n    DatasetReadOneAccess--&gt;DatasetReadOneOwner;\n    DatasetReadOneOwner--&gt;DatasetReadAny;\n</code></pre> <pre><code>    DatasetUpdate--&gt;DatasetUpdateOwner;\n    DatasetUpdateOwner--&gt;DatasetUpdateAny;\n    DatasetDelete--&gt;DatasetDeleteOwner;\n    DatasetDeleteOwner--&gt;DatasetDeleteAny;\n</code></pre>"},{"location":"backendconfig/authorization/authorization_datasets/#authorization-table","title":"Authorization table","text":"<p>Note, merely for visibility reasons the table has been split. Hierarchically, <code>OrigDatablocks</code> and <code>Datablocks</code> belong to <code>Datasets</code>.</p>"},{"location":"backendconfig/authorization/authorization_datasets/#datasets","title":"Datasets","text":"HTTP method Endpoint Endpoint Authorization Anonymous Authenticated User Create Dataset Groups Create Dataset with Pid Groups Create Dataset Privileged Groups Admin Groups Delete Groups Notes POST Datasets DatasetCreate no no Owner, w/o PIDDatasetCreateOwnerNoPid Owner, w/ PIDDatasetCreateOwnerWithPid AnyDatasetCreateAny AnyDatasetCreateAny no POST Datasets/isValid DatasetCreate no no Owner, w/o PIDDatasetCreateOwnerNoPid Owner, W/ PIDDatasetCreateOwnerWithPid AnyDatasetCreateAny AnyDatasetCreateAny no GET Datasets DatasetRead PublicDatasetReadPublic Has AccessDatasetReadAccess Has AccessDatasetReadAccess Has AccessDatasetReadAccess Has AccessDatasetReadAccess AnyDatasetReadyAny no GET Datasets/fullquery DatasetRead PublicDatasetReadManyPublic Has AccessDatasetReadManyAccess Has AccessDatasetReadManyAccess Has AccessDatasetReadManyAccess Has AccessDatasetReadManyAccess AnyDatasetReadAny no GET Datasets/fullfacet DatasetRead PublicDatasetReadManyPublic Has AccessDatasetReadManyAccess Has AccessDatasetReadManyAccess Has AccessDatasetReadManyAccess Has AccessDatasetReadManyAccess AnyDatasetReadAny no GET Datasets/metadataKeys DatasetRead PublicDatasetReadManyPublic Has AccessDatasetReadManyAccess Has AccessDatasetReadManyAccess Has AccessDatasetReadManyAccess Has AccessDatasetReadManyAccess AnyDatasetReadAny no GET Datasets/count DatasetRead PublicDatasetReadManyPublic Has AccessDatasetReadManyAccess Has AccessDatasetReadManyAccess Has AccessDatasetReadManyAccess Has AccessDatasetReadManyAccess AnyDatasetReadAny no GET Datasets/findOne DatasetRead PublicDatasetReadOnePublic Has AccessDatasetReadOneAccess Has AccessDatasetReadOneAccess Has AccessDatasetReadOneAccess Has AccessDatasetReadOneAccess AnyDatasetReadAny no GET Datasets/pid DatasetRead PublicDatasetReadOnePublic Has AccessDatasetReadOneAccess Has AccessDatasetReadOneAccess Has AccessDatasetReadOneAccess Has AccessDatasetReadOneAccess AnyDatasetReadAny no PATCH Datasets/pid DatasetUpdate no no OwnerDatasetUpdateOwner OwnerDatasetUpdateOwner OwnerDatasetUpdateOwner AnyDatasetUpdateAny no PUT Datasets/pid DatasetUpdate no no OwnerDatasetUpdateOwner OwnerDatasetUpdateOwner OwnerDatasetUpdateOwner AnyDatasetUpdateAny no POST Datasets/pid/appendToArrayField DatasetUpdate no no OwnerDatasetUpdateOwner OwnerDatasetUpdateOwner OwnerDatasetUpdateOwner AnyDatasetUpdateAny no DELETE Datasets/pid DatasetDelete no no no no no no AnyDatasetDeleteAny GET Datasets/pid/thumbnail DatasetRead PublicDatasetReadPublic Has AccessDatasetReadAccess Has AccessDatasetReadAccess Has AccessDatasetReadAccess Has AccessDatasetReadAccess AnyDatasetReadAny no POST Datasets/pid/attachments DatasetAttachmentCreate no no OwnerDatasetAttachmentCreateOwner OwnerDatasetAttachmentCreateOwner AnyDatasetAttachmentCreateAny AnyDatasetAttachmentCreateAny no GET Datasets/pid/attachments DatasetAttachmemntRead PublicDatasetAttachmentReadPublic Has AccessDatasetAttachmentReadAccess Has AccessDatasetAttachmentReadAccess Has AccessDatasetAttachmentReadAccess Has AccessDatasetAttachmentReadAccess AnyDatasetAttachmentReadAny no PUT Datasets/pid/attachments/aid DatasetAttachmemntUpdate no no OwnerDatasetAttachmentUpdateOwner OwnerDatasetAttachmentUpdateOwner OwnerDatasetAttachmentUpdateOwner AnyDatasetAttachmentCreateAny no DELETE Datasets/pid/attachments/aid DatasetAttachmemntDelete no no OwnerDatasetAttachmentDeleteOwner OwnerDatasetAttachmentDeleteOwner OwnerDatasetAttachmentDeleteOwner AnyDatasetAttachmentDeleteAny no"},{"location":"backendconfig/authorization/authorization_datasets/#origdatablock","title":"OrigDatablock","text":"HTTP method Endpoint Endpoint Authorization Anonymous Authenticated User Create Dataset Groups Create Dataset with Pid Groups Create Dataset Privileged Groups Admin Groups Delete Groups Notes POST Datasets/pid/origdatablocks DatasetOrigdatablocksCreate no no OwnerDatasetOrigdatablockCreateOwner OwnerDatasetOrigdatablockCreateOwner AnyDatasetOrigdatablockCreateAny AnyDatasetOrigdatablockCreateAny no POST Datasets/pid/origdatablocks/isValid DatasetOrigdatablocksCreate no no OwnerDatasetOrigdatablockCreateOwner OwnerDatasetOrigdatablockCreateOwner AnyDatasetOrigdatablockCreateAny AnyDatasetOrigdatablockCreateAny no GET Datasets/pid/origdatablocks DatasetOrigdatablocksRead PublicDatasetOrigdatablockReadPublic Has AccessDatasetOrigdatablockReadOAccess Has AccessDatasetOrigdatablockReadAccess Has AccessDatasetOrigdatablockReadAccess Has AccessDatasetOrigdatablockReadAccess AnyDatasetOrigdatablockReadAny no PATCH Datasets/pid/origdatablocks/oid DatasetOrigdatablocksUpdate no no OwnerDatasetOrigdatablockUpdateOwner OwnerDatasetOrigdatablockUpdateOwner OwnerDatasetOrigdatablockUpdateOwner AnyDatasetOrigdatablockCreateAny no DELETE Datasets/pid/origdatablocks/oid DatasetOrigdatablocksDelete no no no no no no AnyDatasetOrigdatablockDeleteAny"},{"location":"backendconfig/authorization/authorization_datasets/#datablocks","title":"Datablocks","text":"HTTP method Endpoint Endpoint Authorization Anonymous Authenticated User Create Dataset Groups Create Dataset with Pid Groups Create Dataset Privileged Groups Admin Groups Delete Groups Notes POST Datasets/pid/datablocks DatasetDatablocksCreate no no OwnerDatasetDatablockCreateOwner OwnerDatasetDatablockCreateOwner OwnerDatasetDatablockCreateOwner AnyDatasetDatablockCreateAny no GET Datasets/pid/datablocks DatasetOrigdatablocksRead PublicDatasetDatablockReadPublic Has AccessDatasetDatablockReadAccess Has AccessDatasetDatablockReadAccess Has AccessDatasetDatablockReadAccess Has AccessDatasetDatablockReadAccess AnyDatasetDatablockReadAny no PATCH Datasets/pid/datablocks/oid DatasetDatablocksUpdate no no OwnerDatasetDatablockUpdateOwner OwnerDatasetDatablockUpdateOwner OwnerDatasetDatablockUpdateOwner AnyDatasetDatablockCreateAny no DELETE Datasets/pid/datablocks/oid DatasetDatablocksDelete no no no no no no AnyDatasetDatablockDeleteAny GET Datasets/pid/logbook DatasetLogbookRead no OwnerDatasetLogbookReadOwner OwnerDatasetLogbookReadOwner OwnerDatasetLogbookReadOwner OwnerDatasetLogbookReadOwner AnyDatasetLogbookReadAny no"},{"location":"backendconfig/authorization/authorization_instruments/","title":"Instruments Authorization","text":""},{"location":"backendconfig/authorization/authorization_instruments/#casl-ability-actions","title":"CASL ability actions","text":"<p>This is the list of the permissions methods available for Instrument and all their endpoints</p>"},{"location":"backendconfig/authorization/authorization_instruments/#endpoint-authorization","title":"Endpoint Authorization","text":"<ol> <li>InstrumentCreate</li> <li>InstrumentRead</li> <li>InstrumentUpdate</li> <li>InstrumentDelete</li> </ol>"},{"location":"backendconfig/authorization/authorization_instruments/#priority","title":"Priority","text":"<pre><code>    InstrumentCreate;\n    InstrumentRead;\n    InstrumentUpdate;\n    InstrumentDelete;\n</code></pre>"},{"location":"backendconfig/authorization/authorization_instruments/#authorization-table","title":"Authorization table","text":"HTTP method Endpoint Endpoint Authentication Anonymous Authenticated User Admin Groups Delete Groups Notes POST instruments InstrumentCreate no no InstrumentCreate no - GET instruments InstrumentRead InstrumentRead InstrumentRead InstrumentRead no - GET instruments/id InstrumentRead InstrumentRead InstrumentRead InstrumentRead no - PATCH instruments/id InstrumentUpdate no no InstrumentUpdate no - DELETE instruments/id InstrumentDelete no no no InstrumentDelete -"},{"location":"backendconfig/authorization/authorization_jobs/","title":"Jobs Authorization","text":"<p>Jobs subsystem relies on groups defined in the configuration file for the backend: </p> Configuration Group List Description ADMIN_GROUPS Users of the listed groups can create, modify and read any job. They cannot delete jobs. CREATE_JOB_PRIVILEGED_GROUPS Users of the listed groups can create and read any job. They can only modify jobs that belong to their user or group depending on the configuration of given job (see Job Create Authorization Table ). They cannot delete jobs. UPDATE_JOB_PRIVILEGED_GROUPS Users of the listed groups can modify and read any job. They can only create jobs that belong to their user or group depending on the configuration of given job (see Job Update Authorization Table ). They cannot delete jobs. DELETE_JOB_GROUPS Users whose group is listed here are allowed to delete any job"},{"location":"backendconfig/authorization/authorization_jobs/#casl-ability-actions","title":"CASL ability actions","text":"<p>This is the list of the permission methods available for Jobs and all their endpoints. The authorization for jobs is consistently different from all the other endpoints.</p>"},{"location":"backendconfig/authorization/authorization_jobs/#endpoint-authorization","title":"Endpoint Authorization","text":"<ol> <li>JobCreate</li> <li>JobRead</li> <li>JobUpdate</li> <li>JobDelete</li> </ol>"},{"location":"backendconfig/authorization/authorization_jobs/#data-instance-authorization","title":"(Data) Instance Authorization","text":"<ol> <li>JobCreateConfiguration (The job's create section of the configuration dictates if the user can create the job)</li> <li>JobCreateOwner (Users with this privilege can create jobs for others)</li> <li>JobCreateAny (Users with this privilege can create jobs for any of the users that are defined in the create section of the job configuration)</li> <li>JobReadAccess</li> <li>JobReadAny</li> <li>JobUpdateConfiguration (The job's update section in configuration dictates if the user can update the job)</li> <li>JobUpdateOwner (Users with this privilege can update jobs belonging to others)</li> <li>JobUpdateAny (Users with this privilege can update any job)</li> </ol>"},{"location":"backendconfig/authorization/authorization_jobs/#priority","title":"Priority","text":"<pre><code>    JobCreate--&gt;JobCreateConfiguration;\n    JobCreateConfiguration--&gt;JobCreateAny;\n    JobRead--&gt;JobReadAccess;\n    JobReadAccess--&gt;JobReadAny;\n    JobUpdate--&gt;JobUpdateConfiguration;\n    JobUpdateConfiguration--&gt;JobUpdateAny;\n    JobDelete;\n</code></pre>"},{"location":"backendconfig/authorization/authorization_jobs/#authorization-table","title":"Authorization table","text":"HTTP method Endpoint Endpoint Authentication Anonymous Authenticated Create Jobs Groups Update Jobs Groups Admin Groups Delete Groups POST Jobs JobCreate JobCreateConfiguration JobCreateConfiguration AnyJobsCreateOwner no AnyJobsCreateAny no GET Jobs JobReadMany no Has AccessJobReadAccess Has AccessJobReadAccess no AnyJobReadAny no GET Jobs/jid JobReadOne no Has AccessJobReadAccess Has AccessJobReadAccess no AnyJobReadAny no PATCH Jobs/jid JobUpdate no JobUpdateConfiguration no OwnerJobUpdateOwner AnyJobUpdateAny no DELETE Jobs/jid JobDelete no no no no no no"},{"location":"backendconfig/authorization/authorization_jobs/#job-create-authorization-table","title":"Job Create Authorization Table","text":"<p>The JobCreateConfiguration authorization permissions are configured directly in the create section of the job configuration. Any positive match will result in the user acquiring JobCreate endpoint authorization, which applies to the jobs endpoint <code>POST:Jobs</code> </p> Job Create Authorization Endpoint Authentication Translation Endpoint Authentication Description Instance Authentication Translation Instance Authentication Description #all #all any user can access this endpoint, both anonymous and authenticated #all Any user can create this instance of the job #datasetPublic #all any user can access this endpoint, both anonymous and authenticated #datasetPublic the job instance will be created only if all the datasets listed are public #authenticated #user any valid users can access the endpoint, independently from their groups #user any valid users can create this instance of the job #datasetAccess #all any user can access this endpoint, both anonymous and authenticated #datasetAccess the job instance will be created only if the specified user group or otherwise any of the user's groups has access to all the datasets listed #datasetOwner #all any user can access this endpoint, both anonymous and authenticated #datasetOwner the job instance will be created only if the specified user group or otherwise any of the user's groups is part of all the datasets' owner group @GROUP #all any user can access this endpoint, both anonymous and authenticated GROUP the job instance will be created only if the user belongs to the group specified USER #all any user can access this endpoint, both anonymous and authenticated USER the job instance can be created only by the user indicated #jobAdmin #all any user can access this endpoint, both anonymous and authenticated #jobAdmin the job instance can be created by users of ADMIN_GROUPS and CREATE_JOB_PRIVILEGED only IMPORTANT: use option #all carefully, as it allows anybody to create a new job. It is mostly used for debugging and testing."},{"location":"backendconfig/authorization/authorization_jobs/#job-update-authorization-table","title":"Job Update Authorization Table","text":"<p>The JobUpdateConfiguration authorization permissions are configured directly in the update section of the job configuration. Any positive match will result in the user acquiring  JobUpdate endpoint authorization, which applies to the jobs endpoint <code>PATCH:Jobs/id</code> </p> Job Update Authorization Endpoint Authentication Translation Endpoint Authentication Description Instance Authentication Translation Instance Authentication Description #all #all any user can access this endpoint, both anonymous and authenticated #all Any user can update this job instance #jobOwnerUser #user any user can access this endpoint, both anonymous and authenticated #jobOwnerUser only the user that is listed in field ownerUser can perform the update #jobOwnerGroup #user any user can access this endpoint, both anonymous and authenticated #jobOwnerGroup any user that belongs to the group listed in field ownerGroup can perform the update @GROUP GROUP any user can access this endpoint, both anonymous and authenticated GROUP the job can be updated only by users who belong to the group specified USER USER any user can access this endpoint, both anonymous and authenticated USER the job can be updated only by the user indicated #jobAdmin #all any user can access this endpoint, both anonymous and authenticated #jobAdmin the job instance can be created by users of ADMIN_GROUPS and UPDATE_JOB_PRIVILEGED only <p>IMPORTANT: use option #all carefully, as it allows anybody to update the job. It is mostly used for debugging and testing.</p>"},{"location":"backendconfig/authorization/authorization_jobs/#job-authorization-priority","title":"Job Authorization priority","text":"<p>The endpoint authorization is the most permissive authorization across all the jobs defined. The priority between job create and update authorization is as follows:</p> <pre><code>    all--&gt;user;\n    user--&gt;GROUP;\n    GROUP--&gt;USER;\n    USER--&gt;ADMIN_GROUPS;\n</code></pre>"},{"location":"backendconfig/authorization/authorization_origdatablocks/","title":"OrigDatablock Authorization","text":""},{"location":"backendconfig/authorization/authorization_origdatablocks/#casl-ability-actions","title":"CASL ability actions","text":"<p>This is the list of the permissions methods available for origdatablock and all their endpoints.</p>"},{"location":"backendconfig/authorization/authorization_origdatablocks/#endpoint-authorization","title":"Endpoint Authorization","text":"<ol> <li>OrigdatablockCreate</li> <li>OrigdatablockRead</li> <li>OrigdatablockUpdate</li> <li>OrigdatablockDelete</li> </ol>"},{"location":"backendconfig/authorization/authorization_origdatablocks/#data-instance-authorization","title":"(Data) Instance Authorization","text":"<ol> <li>OrigdatablockCreateOwner</li> <li>OrigdatablockCreateAny</li> <li>OrigdatablockReadManyPublic</li> <li>OrigdatablockReadManyAccess</li> <li>OrigdatablockReadManyOwner</li> <li>OrigdatablockReadOnePublic</li> <li>OrigdatablockReadOneAccess</li> <li>OrigdatablockReadOneOwner</li> <li>OrigdatablockReadAny</li> <li>OrigdatablockUpdateOwner</li> <li>OrigdatablockUpdateAny</li> <li>OrigdatablockDeleteAny</li> </ol>"},{"location":"backendconfig/authorization/authorization_origdatablocks/#priority","title":"Priority","text":"<pre><code>    DatasetOrigdatablockCreate--&gt;DatasetOrigdatablockCreateOwner;\n    DatasetOrigdatablockCreateOwner--&gt;DatasetOrigdatablockCreateAny;\n</code></pre> <pre><code>    DatasetOrigdatablockRead--&gt;DatasetOrigdatablockReadManyPublic;\n    DatasetOrigdatablockReadManyPublic--&gt;DatasetOrigdatablockReadManyAccess;\n    DatasetOrigdatablockReadManyAccess--&gt;DatasetOrigdatablockReadAny;\n    DatasetOrigdatablockRead--&gt;DatasetOrigdatablockReadOnePublic;\n    DatasetOrigdatablockReadOnePublic--&gt;DatasetOrigdatablockReadOneAccess;\n    DatasetOrigdatablockReadOneAccess--&gt;DatasetOrigdatablockReadAny;\n</code></pre> <pre><code>    DatasetOrigdatablockUpdate--&gt;DatasetOrigdatablockUpdateOwner;\n    DatasetOrigdatablockUpdateOwner--&gt;DatasetOrigdatablockUpdateAny;\n</code></pre> <pre><code>    DatasetOrigdatablockDelete--&gt;DatasetOrigdatablockDeleteOwner;\n    DatasetOrigdatablockDeleteOwner--&gt;DatasetOrigdatablockDelteAny;\n</code></pre>"},{"location":"backendconfig/authorization/authorization_origdatablocks/#authorization-table","title":"Authorization table","text":"HTTP method Endpoint Endpoint Authentication Anonymous Authenticated User Create Dataset Groups Create Dataset with Pid Groups Create Dataset Privileged Groups Admin Groups Delete Groups Notes POST origdatablocks OrigdatablockCreate no no OwnerOrigdatablockCreateOwn OwnerOrigidatablockCreateOwn AnyOrigdatablockCreateAny Any OrigdatablockCreateAny no POST origdatablocks/isValid OrigdatablockCreate no no OwnerOrigdatablockCreateOwn OwnerOrigdatablockCreateOwn AnyOrigdatablockCreateAny AnyOrigdatablockCreateAny no GET origdatablocks OrigdatablockRead PublicOrigdatablockReadManyPublic Has AccessOrigdatablockReadManyAccess Has AccessOrigdatablockReadManyAccess Has AccessOrigdatablockReadManyAccess Has AccessOrigdatablockReadManyAccess AnyOrigdatablockReadAny no GET origdatablocks/fullquery OrigdatablockRead PublicOrigdatablockReadManyPublic Has AccessOrigdatablockReadManyAccess Has AccessOrigdatablockReadManyAccess Has AccessOrigdatablockReadManyAccess Has AccessOrigdatablockReadManyAccess AnyOrigdatablockReadAny no GET origdatablocks/fullquery/files OrigdatablockRead PublicOrigdatablockReadManyPublic Has AccessOrigdatablockReadManyAccess Has AccessOrigdatablockReadManyAccess Has AccessOrigdatablockReadManyAccess Has AccessOrigdatablockReadManyAccess AnyOrigdatablockReadAny no GET origdatablocks/fullfacet OrigdatablockRead PublicOrigdatablockReadManyPublic Has AccessOrigdatablockReadManyAccess Has AccessOrigdatablockReadManyAccess Has AccessOrigdatablockReadManyAccess Has AccessOrigdatablockReadManyAccess AnyOrigdatablockReadAny no GET origdatablocks/oid OrigdatablockRead PublicOrigdatablockReadOnePublic Has AccessOrigdatablockReadOneAccess Has AccessOrigdatablockReadOneAccess Has AccessOrigdatablockReadOneAccess Has AccessOrigdatablockReadOneAccess AnyOrigdatablockReadAny no PATCH origdatablocks/oid OrigdatablockUpdate no no OwnerOrigdatablockUpdateOwner OwnerOrigdatablockUpdateOwner OwnerOrigdatablockUpdateOwner AnyOrigdatablockUpdateAny no DELETE origdatablocks/oid OrigdatablockDelete no no no no no no AnyOrigdatablockDeleteAny"},{"location":"backendconfig/authorization/authorization_proposals/","title":"Proposals Authorization","text":""},{"location":"backendconfig/authorization/authorization_proposals/#casl-ability-actions","title":"CASL ability actions","text":"<p>This is the list of the permissions methods available for Proposals and all their endpoints.</p>"},{"location":"backendconfig/authorization/authorization_proposals/#endpoint-authorization","title":"Endpoint Authorization","text":"<ol> <li>ProposalCreate</li> <li>ProposalRead</li> <li>ProposalUpdate</li> <li>ProposalDelete</li> <li>ProposalAttachmentCreate</li> <li>ProposalAttachmentRead</li> <li>ProposalAttachmentUpdate</li> <li>ProposalAttachmentDelete</li> <li>ProposalDatasetRead</li> </ol>"},{"location":"backendconfig/authorization/authorization_proposals/#data-instance-authorization","title":"(Data) Instance Authorization","text":"<ol> <li>ProposalCreateOwner</li> <li>ProposalCreateAny</li> <li>ProposalReadManyPublic</li> <li>ProposalReadManyAccess</li> <li>ProposalReadManyOwner</li> <li>ProposalReadOnePublic</li> <li>ProposalReadOneAccess</li> <li>ProposalReadOneOwner</li> <li>ProposalReadAny</li> <li>ProposalUpdateOwner</li> <li>ProposalUpdateAny</li> <li>ProposalDeleteOwner</li> <li>ProposalDeleteAny</li> <li>ProposalAttachmentCreateOnwer</li> <li>ProposalAttachmentCreateAny</li> <li>ProposalAttachmentReadManyPublic</li> <li>ProposalAttachmentReadManyAccess</li> <li>ProposalAttachmentReadManyOwner</li> <li>ProposalAttachmentReadManyAny</li> <li>ProposalAttachmentUpdateOwner</li> <li>ProposalAttachmentUpdateAny</li> <li>ProposalAttachmentDeleteOwner</li> <li>ProposalAttachmentDeleteAny</li> <li>ProposalDatasetReadPublic</li> <li>ProposalDatasetReadAccess</li> <li>ProposalDatasetReadOwner</li> <li>ProposalDatasetReadAny</li> </ol>"},{"location":"backendconfig/authorization/authorization_proposals/#priority","title":"Priority","text":"<pre><code>    ProposalCreate--&gt;ProposalsCreateOwner;\n    ProposalCreateOwner--&gt;ProposalCreateAny;\n</code></pre> <pre><code>    ProposalRead--&gt;ProposalReadManyPublic;\n    ProposalReadManyPublic--&gt;ProposalReadManyAccess;\n    ProposalReadManyAccess--&gt;ProposalReadManyOwner;\n    ProposalReadManyOwner--&gt;ProposalReadAny;\n    ProposalRead--&gt;ProposalReadOnePublic;\n    ProposalReadOnePublic--&gt;ProposalReadOneAccess;\n    ProposalReadOneAccess--&gt;ProposalReadOneOwner;\n    ProposalReadOneOwner--&gt;ProposalReadAny;\n</code></pre> <pre><code>    ProposalUpdate--&gt;ProposalUpdateOwner;\n    ProposalUpdateOwner--&gt;ProposalUpdateAny;\n    ProposalDelete--&gt;ProposalDeleteOwner;\n    ProposalDeleteOwner--&gt;ProposalDeleteAny;\n</code></pre> <pre><code>    ProposalAttachmentCreate--&gt;ProposalAttachmentCreateOnwer;\n    ProposalAttachmentCreateOnwer--&gt;ProposalAttachmentCreateAny;\n    ProposalAttachmentRead--&gt;ProposalAttachmentReadManyPublic;\n    ProposalAttachmentReadManyPublic--&gt;ProposalAttachmentReadManyAccess;\n    ProposalAttachmentReadManyAccess--&gt;ProposalAttachmentReadManyOwner;\n    ProposalAttachmentReadManyOwner--&gt;ProposalAttachmentReadManyAny;\n    ProposalAttachmentUpdate--&gt;ProposalAttachmentUpdateOwner;\n    ProposalAttachmentUpdateOwner--&gt;ProposalAttachmentUpdateAny;\n    ProposalAttachmentDelete--&gt;ProposalAttachmentDeleteOwner;\n    ProposalAttachmentDeleteOwner--&gt;ProposalAttachmentDeleteAny;\n</code></pre> <pre><code>    ProposalDatasetRead--&gt;ProposalDatasetReadPublic;\n    ProposalDatasetReadPublic--&gt;ProposalDatasetReadAccess;\n    ProposalDatasetReadAccess--&gt;ProposalDatasetReadOwner;\n    ProposalDatasetReadOwner--&gt;ProposalDatasetReadAny;\n</code></pre>"},{"location":"backendconfig/authorization/authorization_proposals/#authorization-table","title":"Authorization table","text":"HTTP method Endpoint Endpoint Authentication Anonymous Authenticated User Proposals Groups Admin Groups Delete Groups Notes POST Proposals ProposalCreate no no AnyProposalCreateAny AnyProposalCreateAny no GET Proposals ProposalRead PublicProposalReadManyPublic Has AccessProposalReadManyAccess Has AccessProposalReadManyAccess AnyProposalReadAny no GET Proposals/fullquery ProposalRead PublicProposalReadManyPublic Has AccessProposalReadManyAccess Has AccessProposalReadManyAccess AnyProposalReadAny no GET Proposals/fullfacet ProposalRead PublicProposalReadManyPublic Has AccessProposalReadManyAccess Has AccessProposalReadManyAccess AnyProposalReadAny no GET Proposals/pid ProposalRead PublicProposalReadOnePublic Has AccessProposalReadOneAccess Has AccessProposalReadOneAccess AnyProposalReadAny no GET Proposals/fullquery ProposalRead PublicProposalReadOnePublic Has AccessProposalReadOneAccess Has AccessProposalReadOneAccess AnyProposalReadAny no PATCH Proposals/pid ProposalUpdate no no AnyProposalUpdateAny AnyProposalUpdateAny no DELETE Proposals/pid ProposalDelete no no no no AnyProposalDeleteAny POST Proposals/pid/attachements ProposalAttachementCreate no no AnyProposalAttachmentCreateAny AnyProposalAttachmentCreateAny no GET Proposals/pid/attachements ProposalAttachmentRead PublicProposalAttachmentReadManyPublic Has AccessProposalAttachmentReadManyAccess Has AccessProposalAttachmentReadManyAccess AnyProposalAttachmentReadManyAny no PATCH Proposals/pid/attachments/aid ProposalAttachmentUpdate no no OwnerProposalAttachmentUpdateOwner AnyProposalAttachmentUpdateAny no DELETE Proposals/pid/attachment/aid ProposalAttachmentDelete no no OnwerProposalAttachmentDeleteOwner AnyProposalAttachmentDeleteAny no GET Proposals/pid/datasets ProposalDatasetRead PublicProposalDatasetReadOnePublic Has AccessProposalDatasetReadOneAccess Has AccessProposalDatasetReadOneAccess AnyProposalDatasetReadOneAny no"},{"location":"backendconfig/authorization/authorization_samples/","title":"Samples Authorization","text":""},{"location":"backendconfig/authorization/authorization_samples/#casl-ability-actions","title":"CASL ability actions","text":"<p>This is the list of the permissions methods available for Samples and all their endpoints</p>"},{"location":"backendconfig/authorization/authorization_samples/#endpoint-authorization","title":"Endpoint Authorization","text":"<ul> <li>SampleCreate</li> <li>SampleRead</li> <li>SampleUpdate</li> <li>SampleDelete</li> <li>SampleAttachmentCreate</li> <li>SampleAttachmentRead</li> <li>SampleAttachmentUpdate</li> <li>SampleAttachmentDelete</li> <li>SampleDatasetRead</li> </ul>"},{"location":"backendconfig/authorization/authorization_samples/#data-instance-authorization","title":"(Data) Instance Authorization","text":"<ul> <li>SampleCreateOwner</li> <li>SampleCreateAny</li> <li>SampleReadManyPublic</li> <li>SampleReadManyAccess</li> <li>SampleReadManyOwner</li> <li>SampleReadOnePublic</li> <li>SampleReadOneAccess</li> <li>SampleReadOneOwner</li> <li>SampleReadAny</li> <li>SampleUpdateOwner</li> <li>SampleUpdateAny</li> <li>SampleDeleteOwner</li> <li>SampleDeleteAny</li> <li>SampleAttachmentCreateOwner</li> <li>SampleAttachmentCreateAny</li> <li>SampleAttachmentReadManyPublic</li> <li>SampleAttachmentReadManyAccess</li> <li>SampleAttachmentReadManyOwner</li> <li>SampleAttachmentReadManyAny</li> <li>SampleAttachmentUpdateOwner</li> <li>SampleAttachmentUpdateAny</li> <li>SampleAttachmentDeleteOwner</li> <li>SampleAttachmentDeleteAny</li> <li>SampleDatasetReadPublic</li> <li>SampleDatasetReadAccess</li> <li>SampleDatasetReadOwner</li> <li>SampleDatasetReadAny</li> </ul>"},{"location":"backendconfig/authorization/authorization_samples/#priority","title":"Priority","text":"<pre><code>graph LR;\n    SampleCreate--&gt;SampleCreateOwner;\n    SampleCreateOwner--&gt;SampleCreateAny;\n    SampleRead--&gt;SampleReadManyPublic;\n    SampleReadManyPublic--&gt;SampleReadManyAccess;\n    SampleReadManyAccess--&gt;SampleReadManyOwner;\n    SampleReadManyOwner--&gt;SampleReadAny;\n    SampleRead--&gt;SampleReadOnePublic;\n    SampleReadOnePublic--&gt;SampleReadOneAccess;\n    SampleReadOneAccess--&gt;SampleReadOneOwner;\n    SampleReadOneOwner--&gt;SampleReadAny;\n    SampleUpdate--&gt;SampleUpdateOwner;\n    SampleUpdateOwner--&gt;SampleUpdateAny;\n    SampleDelete--&gt;SampleDeleteOwner;\n    SampleDeleteOwner--&gt;SampleDeleteAny;\n    SampleAttachmentCreate--&gt;SampleAttachmentCreateOwner;\n    SampleAttachmentCreateOwner--&gt;SampleAttachmentCreateAny;\n    SampleAttachmentRead--&gt;SampleAttachmentReadManyPublic;\n    SampleAttachmentReadManyPublic--&gt;SampleAttachmentReadManyAccess;\n    SampleAttachmentReadManyAccess--&gt;SampleAttachmentReadManyOwner;\n    SampleAttachmentReadManyOwner--&gt;SampleAttachmentReadManyAny;\n    SampleAttachmentUpdate--&gt;SampleAttachmentUpdateOwner;\n    SampleAttachmentUpdateOwner--&gt;SampleAttachmentUpdateAny;\n    SampleAttachmentDelete--&gt;SampleAttachmentDeleteOwner;\n    SampleAttachmentDeleteOwner--&gt;SampleAttachmentDeleteAny;\n    SampleDatasetRead--&gt;SampleDatasetReadPublic;\n    SampleDatasetReadPublic--&gt;SampleDatasetReadAccess;\n    SampleDatasetReadAccess--&gt;SampleDatasetReadOwner;\n    SampleDatasetReadOwner--&gt;SampleDatasetReadAny;\n</code></pre>"},{"location":"backendconfig/authorization/authorization_samples/#authorization-table","title":"Authorization table","text":"HTTP method Endpoint Endpoint Authentication Anonymous Authenticated User Sample Groups Sample Privileged Groups Admin Groups Delete Groups Notes POST Samples SampleCreate no no OwnerSampleCreateOwner AnySampleCreateAny AnySampleCreateAny no GET Samples SampleRead PublicSampleReadManyPublic Has AccessSampleReadManyAccess Has AccessSampleReadManyAccess Has AccessSampleReadManyAccess AnySampleReadAny no GET Samples/fullquery SampleRead PublicSampleReadManyPublic Has AccessSampleReadManyAccess Has AccessSampleReadManyAccess Has AccessSampleReadManyAccess AnySampleReadAny no GET Samples/fullfacet SampleRead PublicSampleReadManyPublic Has AccessSampleReadManyAccess Has AccessSampleReadManyAccess Has AccessSampleReadManyAccess AnySampleReadAny no GET Samples/pid SampleRead PublicSampleReadOnePublic Has AccessSampleReadOneAccess Has AccessSampleReadOneAccess Has AccessSampleReadOneAccess AnySampleReadAny no GET Samples/fullquery SampleRead PublicSampleReadOnePublic Has AccessSampleReadOneAccess Has AccessSampleReadOneAccess Has AccessSampleReadOneAccess AnySampleReadAny no PATCH Samples/pid SampleUpdate no no OwnerSampleUpdateOwn OwnerSampleUpdateOwn AnySampleUpdateAny no DELETE Samples/pid SampleDelete no no no no no AnySampleDeleteAny POST Samples/pid/Attachments SampleAttachmentCreate no no OwnerSampleAttachmentCreateOwner AnySampleAttachmentCreateAny AnySampleAttachmentCreateAny no GET Samples/pid/Attachments SampleAttachmentRead PublicSampleAttachmentReadManyPublic Has AccessSampleAttachmentReadManyAccess Has AccessSampleAttachmentReadManyAccess Has AccessSampleAttachmentReadManyAccess AnySampleAttachmentReadManyAny no DELETE Samples/pid/attachment/aid SampleAttachmentDelete no no OwnerSampleAttachmentDeleteOwner OwnerSampleAttachmentDeleteOwner AnySampleAttachmentDeleteAny AnySampleAttachmentDeleteAny GET Samples/pid/datasets SampleDatasetRead PublicSampleDatasetReadOnePublic Has AccessSampleDatasetReadOneAccess Has AccessSampleDatasetReadOneAccess Has AccessSampleDatasetReadOneAccess AnySampleDatasetReadOneAny no"},{"location":"backendconfig/authorization/authorization_users/","title":"Users Authorization","text":""},{"location":"backendconfig/authorization/authorization_users/#casl-ability-actions","title":"CASL ability actions","text":"<p>This is the list of the permissions methods available for datasets and all their endpoints.</p>"},{"location":"backendconfig/authorization/authorization_users/#endpoint-authorization","title":"Endpoint authorization","text":"<ol> <li>UserLogin</li> <li>UserRead</li> <li>UserCreate</li> <li>UserUpdate</li> <li>UserPassword</li> <li>UserDelete</li> </ol>"},{"location":"backendconfig/authorization/authorization_users/#instance-authorization","title":"Instance authorization","text":"<ol> <li>UserReadOwn</li> <li>UserReadAny</li> <li>UserCreateOwn</li> <li>UserCreateAny</li> <li>UserUpdateOwn</li> <li>UserUpdateAny</li> <li>UserPasswordOwn</li> <li>UserPasswordAny</li> <li>UserDeleteAny</li> </ol>"},{"location":"backendconfig/authorization/authorization_users/#priority","title":"Priority","text":"<pre><code>    UserLogin(E)\n    UserCreate(E)--&gt;UserCreateOwn(I)--&gt;UserCreateAny(I);\n    UserRead(E)--&gt;UserReadOwn(I)--&gt;UserReadAny(I);\n    UserUpdate(E)--&gt;UserUpdateOwner(I)--&gt;UserUpdateAny(I);\n    UserPassword(E)--&gt;UserPasswordOwner(I)--&gt;UserPasswordAny(I);\n    UserDelete(E)--&gt;UserDeleteOwn(I)--&gt;UserDeleteAny(I);\n</code></pre>"},{"location":"backendconfig/authorization/authorization_users/#authorization-table","title":"Authorization table","text":"HTTP method Endpoint Endpoint Authorization Anonymous Authenticated User User Privileged Groups Admin Groups User Delete Groups POST Users/jwt UserRead no OwnUserReadOwn no no no POST Users/login UserLogin no no no no no GET Users/id UserRead no OwnUserReadOwn AnyUserReadAny AnyUserReadAny no GET Users/id/userIdentity UserRead no OwnUserReadOwn AnyUserReadAny AnyUserReadAny no POST Users/id/settings UserCreate no OwnUserCreateOwn AnyUserCreateAny AnyUserCreateAny no GET Users/id/settings UserUpdate no OwnUserReadOwn AnyUserReadAny Any UserReadAny no PUT Users/id/settings UserUpdate no OwnUserUpdateOwn AnyUserUpdateAny AnyUserUpdateAny no PATCH Users/id/settings UserUpdate no OwnUserUpdateOwn AnyUserUpdateAny AnyUserUpdateAny no PATCH Users/id/password UserPassword no OwnUserPasswordOwn AnyUserPasswordAny AnyUserPasswordAny no DELETE Users/id UserDelete no no no no AnyUserDeleteAny DELETE Users/id/settings UserDelete no no no no AnyUserDeleteAny GET Users/id/authorization/dataset/create UserRead no OwnUserReadOwn OwnUserReadOwn AnyUserReadAny no GET Users/logout UserLogout no OwnUserLogoutOwn no no no GET useridentities/findOne UserRead no OwnUserReadOwn AnyUserReadAny AnyUserReadAny no"},{"location":"datasets/","title":"Datasets","text":"<p>SciCat datasets are sets of metadata and can include several files which e.g. comprise a self-contained measurement - which is fully customizeable during ingestion of metadata. Users can search, view different formats (e.g. in tree, tables or as JSON) of the dataset and list them. </p> <p>To group and tag datasets is depicted here. Datasets can also be issued to be published: either removing the restricted view or triggering the process of obtaining a DOI for the selected datasets. For more details see publication of SciCat datasets.</p>"},{"location":"datasets/#how-to-search-for-datasets","title":"How to search for datasets","text":"<p>You can use several places to query your datasets: </p> <ul> <li>on the top the search bar and</li> <li>on the left in the filter &amp; conditions column. The search is configurable to show only what you would like to see and you can define your own conditions making use of your specific scientific metadata.</li> </ul> <p>The bar looks like this: </p> <p>Filtering and condtions can be applied like that. On the very left one sees this column:</p> <p></p> <p>If you chose \"More Filters\" a pop-up window appears where you can chose which of the filters you want to display. You can also add your own conditions as well (visible in the background under conditions): </p>"},{"location":"datasets/#dataset-file-listing","title":"Dataset file listing","text":"<p>Here is the view of files belonging to a dataset: Below the PID on the top, one finds the tab Datafiles: </p> <p>Do not forget to reset your filters if you will be searching with new criteria! </p>"},{"location":"datasets/#dataset-attachments","title":"Dataset attachments","text":"<p>What kind of attachement can be saved? Will they be searchable? Can also other formats be attached than pngs?</p> <p>On the dataset details page, you can click on the Attachments tab </p> <p>Simply follow the instructions to upload an image. The size is restricted to be below 16 MB.</p>"},{"location":"datasets/#view-raw-json-data","title":"View raw JSON data","text":"<p>Scientific meta data is shown in JSON under its section and looks like this: </p>"},{"location":"datasets/#get-raw-json-data","title":"Get raw JSON data","text":"<p>One can also get the JSON file via the swagger API. If set up, one can directly access the API endpoints of SciCat backend. Usually the address is in the form: <code>my-scicat-instance.country/explorer</code>, swagger is accessible via the explorer. One needs to authenticate by copying the token from the GUI into the field authorize, then find the dataset of interest, by trying it out it will display you dataset and you can download it in JSON format.</p>"},{"location":"datasets/#edit-scientific-meta-data","title":"Edit Scientific meta data","text":"<p>If enabled, fields in the scientific metadata can be modified and edited by the owner of the data by hitting the \"Edit\" Icon. The user can add,remove or change metadata fields, every change will create a new record in the databse with it's history [feature is soon available again from 2025-07-02].</p> <p></p>"},{"location":"datasets/#properties-of-a-dataset-in-scicat","title":"Properties of a dataset in SciCat","text":"<p>In the section General information one can input names, owner, PID, data type and more. Additional information is displayed on the detailed dataset overview page:  NOTE THERE ARE OBVIOUSLY THINGS TO BE FIXED!! </p>"},{"location":"datasets/#new-developments-on-dataset-types","title":"New developments on dataset types","text":"<p>Generalize datatypes to remove restrictions of <code>raw</code> and <code>derived</code> types.</p> <p>datasetTypes</p>"},{"location":"datasets/Publishing/","title":"Publishing SciCat datasets","text":"<p>There are two ways of publishing datasets in SciCat via the GUI: one using the \"publish button\" for each dataset, and the other when registering a selection of datasets for a DOI according to DataCite standards. The first step is included in the second one.  If you want a more advanced option for full exploitation of the available endpoints of SciCat, see here.</p> <p>A more technical description of the workflow can be found here.</p>"},{"location":"datasets/Publishing/#publish-without-doi-registration","title":"Publish without DOI registration","text":"<p>Using the \"publish button\" allows for making a dataset visible within the catalogue for a non-authenticated user. Each dataset has this button on the top right.   </p>"},{"location":"datasets/Publishing/#publish-with-doi-registeration","title":"Publish with DOI registeration","text":"<p>The user can select one or several datasets for DOI (Digital Object Identifier) registration producing a record in DataCite, a DOI provider, pointing to a local detailed landing page. SciCat offers a DataCite conform schema during the workflow. Any data that is known to the data catalog can be published and the publication workflow goes as follows:</p> <ol> <li>The logged in user can define a set of datasets to be published.</li> <li>That user assigns metadata relevant to the publication of the datasets, such as title, author (currently the name(s) under 'Creator'), abstract etc. One can work on it at a later stage, too and re-edit the registration. Note, that no editing will be allowed once the registration request has been sent.</li> <li>A DOI is assigned to the published data which can e.g. be used to link from a journal article to the data.</li> <li>It makes the data publicly available by providing a detailed landing page that describes the data.</li> <li>It publishes the DOI to the worldwide DOI system from Datacite.</li> </ol> <p>So the first step is to select the datasets that should be published:</p> <p></p> <p>Then by hitting the \"Add to Cart\" button these datasets are available in the Cart. This step can be repeated to add further datasets. Once the selection is finished you open the Cart ( click on the Cart symbol and choose actions ) to see the selected datasets:</p> <p></p> <p>Here you can still change your selection, remove datasets etc. Once this is finished simply hit the publish button. This leads you to the following screen:</p> <p></p> <p>Some of these fields will be pre-filled with information derived from the proposal data, such as the abstract. Independent of the pre-filling you can change the contents as you like until you are satisfied. Then hit the publish button, which leads you to the resulting display page:</p> <p></p> <p>Initially the status field is in state \"pending\". This means, the published data information has been stored, but not yet made public to the worldwide DOI system, and no landing page has been created yet. This gives the possibility, that (potentially another person) can have  a look at the data and do further editing by hitting the Edit button:</p> <p></p> <p>Once this is finished one can hit the \"register\" button (not shown in previous screenshot, because already in state registered)to register the DOI and thus making the data public. The resulting public landing page for this data then looks somethink like this</p> <p></p> <p>Finally you can have a look at all the published data by going to the Published Data menu item: by clicking the user icon at the top right corner and choosing \"Published Data\":</p> <p></p>"},{"location":"datasets/PublishingAdvanced/","title":"Publishing SciCat datasets Advanced","text":"<p>The previously described options to publish datasets in SciCat - the process of registration of a selection of datasets - is here outlined in a more technical way.</p>"},{"location":"datasets/PublishingAdvanced/#implementation-workflow-target","title":"Implementation workflow target","text":"<p>This diagram shows the essential steps in the workflow to be implemented. Please note, that SciCat datasets are always only meta datasets, SciCat has no direct to the storage system there is no default coupling to such systems.</p>"},{"location":"datasets/PublishingAdvanced/#1-create-a-list-of-selected-datasets","title":"1. Create a list of selected datasets","text":"<p>User can select datasets to create a dataset list; more datasets can be added and removed in several sessions. He can cancel the process at any time. New will be that while examining single datasets he can directly add or remove them to or from the selection in the cart. Before proceeding, the user will be asked to verify the selection of datasets. The user has finalized the dataset selection for which he wants to minted a DOI.</p>"},{"location":"datasets/PublishingAdvanced/#internal-review-to-be-implemented","title":"Internal review (to be implemented)","text":"<p>Some institutions may introduce an internal review step at this point: other authenticated user (as part of a dedicated reviewer-group) review the selected datasets. If OK, proceed to next form and the initial user can continue the minting process.</p>"},{"location":"datasets/PublishingAdvanced/#2-fill-the-form-for-this-dataset-selection","title":"2. Fill the form for this dataset selection","text":"<p>The user will be forwarded to a form where he/she provides metadata specific to this selection already conform to DataCite metadata fields to match site specific information about e.g. grants, associated projects, etc. All selected datasets will be made public. Owners and Admins are allowed to update this form. Again this shall be possible within several sessions.</p>"},{"location":"datasets/PublishingAdvanced/#3-publish-the-selection","title":"3. Publish the selection","text":"<p>After hitting button all selected datasets become publicly visible: not only the owner can view all the metadata of the data, date of creation, associated files names, location, PI, etc. This is prerequisite for DOI registration.  </p>"},{"location":"datasets/PublishingAdvanced/#4-doi-registration","title":"4. DOI registration","text":"<p>Before hitting the registration button the data selection does have an \"internal\" DOI which is an unregistered DOI clearly indicated by the state of this registration request. When hitting the button register all the meta data will be forwarded to DOI provider DataCite if configured, see backend config. For quality control your site may run in between an external service before forwarding the request. Pending request is indicated until the request if forwarded to DataCite. Note, from then on no more changes are possible for the requester. The concept of DOIs is to never change the metadata/data of the DOI.</p>"},{"location":"datasets/PublishingAdvanced/#5-for-admins-only","title":"5. For Admins only","text":"<p>In extremely rare cases and only if justified, i.e. in case of great errors an update can be made by admins only.</p> <p></p>"},{"location":"datasets/datasetTypes/","title":"Datasets Types","text":"<p>A new feature was introduced: instead of only providing <code>raw</code> and <code>derived</code> custom dataset types are now available, e.g. for the proposed dataset collections (hierarchical grouping). Control of which types are allowed should be on the site administration side and be configurable, see also PR. </p>"},{"location":"datasets/datasetTypes/#how-is-this-new-dataset-type-used","title":"How is this new dataset type used?","text":"<p>Add any type into a separate JSON named <code>datasetTypes.json</code>.</p>"},{"location":"datasets/datasetTypes/#changes-made","title":"Changes made","text":"<ul> <li>configuration: add new datasetTypes field and support to read in a json file for custom datasest types (either by env variable or default location \"datasetTypes.json\")</li> <li>add support for custom dataset types in dataset schema</li> <li>dataset controller: update endpoints and validation methods to accept custom dataset types.</li> </ul>"},{"location":"datasets/datasetTypes/#examples-of-usage","title":"Examples of usage","text":"<p>Abstract layer of dataset types, e.g. type <code>collection</code> defined with more, other or less properties or information per dataset. Can be tailored to site-specific adoptions.</p>"},{"location":"datasets/grouping_tagging_ds/","title":"Grouping datasets","text":"<p>An easy way of quickly grouping some of the datasets is the option to tag each dataset individually and then search by this tag. In the General Information of the dataset one can EDIT it by adding a new KEYWORD (note Keywords are not case sensitive). Saving this keyword enables a search on them at a later point. </p> <p>Here one sees the EDIT button (bottom right). </p> <p>Having added your keywords you can use them to search. SciCat directly indicates the number of datasets in the database visible to you </p> <p>on which one can filter (left sidebar) showing all results with e.g. \"myowntagtest\": </p>"},{"location":"login/","title":"Login","text":"<p>To get access to all the data, for which you have read access, you first have to login. Otherwise you can browse only public datasets, see anonymous browsing.</p> <p>To login hit the \"Sign in\" Icon at the top right corner.</p> <p></p> <p>There are two types of account associated with the DataCatalog: Functional and User. A functional account will primarily be used by software and system administrators to deal with backups and other tasks.</p> <p>User accounts are tied into the login system that is used by your institution, for example: Active Directory. You are able to log in to the system using the same credentials you use on that account. This process is called authenitication in IT tech terminology</p> <p>When you login as a user your user management system will assign groups to the logged in user. Each dataset is also assigned to one such group (via the so called ownerGroup field), and you can view the datasets only, if you are member of the corresponding group. The logic that defines, what parts of the data you can see, is called \"authorization\" in IT terminology. The first page you'll see after login is the \"Dashboard\".</p> <p>Another  example login page from PSI is here</p> <p></p>"},{"location":"login/Anonymous/","title":"Anonymous View","text":"<p>As soon as you visit the starting page of the GUI application, and you are not yet logged in, you will see a list of datasets, which have been published, and can therefore be looked at anonymously:</p> <p>You can filter the datasets by choosing the \"facets\" on the left navigation section (e.g. in the screenshot for the location field a value of \"V20\" was selected).</p> <p></p> <p>From this list you can choose a particular dataset to see the details of this dataset</p> <p></p>"},{"location":"login/Dashboard/","title":"Dashboard","text":"<p>The dashboard is the first page that you see independent of whether you are logged in or not. When set to datasets as main access point, it will show an overview of all datasets that you have access to. If you do not login you see those that are public. </p> <p></p> <p>SciCat offers now new features for viewing metadata as one likes with adjustable columns. </p> <p></p> <p>You can change the columns to be shown by chosing from the three right dots \"Column setting\" and select those you would like. One can also drag columns by hovering over dots that appear just next to the label, click, pull it where you want it und release. </p> <p></p> <p>One can</p> <ol> <li>sort columns (click on the name and pull)</li> <li>adjust width of columns (left block of dots)</li> <li>remove or add columns (selection from Column settings)</li> <li>invert order of display (click arrow next to the name)</li> <li>apply a filter directly on that dataset with various options (\"contains\", \"equals\", \"startsWith\", \"endsWith\", \"empty\", \"notEmpty\") and either add (+), or (||) and exclude (x) another filter.</li> </ol> <p></p>"},{"location":"login/Dashboard/#menu-access-to-different-information-pages","title":"Menu access to different information pages","text":"<p>You can always navigate to other parts of the application, simply by clicking on the user icon on the top right corner </p> <p></p>"},{"location":"login/Dashboard/#finding-datasets","title":"Finding Datasets","text":"<p>SciCat provides several possibilities for finding the right datasets. One can use the top search bar, one can narrow down your selection by applying filters and/or conditions and the user can search on scientific metadata as well.</p>"},{"location":"login/Dashboard/#using-filters-and-conditions","title":"Using Filters and Conditions","text":"<p>On the left one can apply most common filters. Currently there are</p> <ol> <li>Location: location of creation of the dataset.</li> <li>PID: Identifier of the dataset.</li> <li>Groups: who owns the dataset.</li> <li>Type: data type - e.g. raw data or derived data.</li> <li>Keywords: tags added to the dataset.</li> <li>Start - End Date: show datasets captured between the dates that you have set.</li> <li>Text: which searches across dataset name and description.</li> </ol> <p>The text fields provide an auto completion, which becomes visible as you type. </p> <p>You can click on the date calendar to select the start date and a second to select end date. Make sure you select 2 dates.</p> <p>One can configure the selection of filters and add specific conditions. An example shows two additional conditions added: </p>"},{"location":"login/Dashboard/#view-details","title":"View Details","text":"<p>To view a dataset simply click on it in the table and a more detailed view will load (this is covered in the datasets section)</p>"},{"location":"operator/","title":"Welcome to SciCat Manual for Admins","text":"<p>This is a short guide containing most of how SciCat can be operated. Many technical aspects are already described in the scicatlive documentation.</p> <p>We highlight in more detail aspects for someone exploring core SciCat software. </p> <ul> <li>How to set up development versions of the new version of dataset endpoints.</li> <li>How to configure SciCat to mint DOIs.</li> <li>How to integrate SciCat with other systems.</li> </ul>"},{"location":"operator/datasetsv4/","title":"How to run new dataset endpoint in v4","text":"<p>For now one can run and play with the new version of dataset endpoints v4. Here is how to set it up:</p> <ol> <li>Pre-requisits: admin rights, git, docker, nodejs (v.20.18.2) and npm (v10.8.2).</li> <li>For frontend to run, install angular like this: \"npm install -g @angular\"</li> <li>Git clone frontend and backend repository.</li> <li>Launch \"npm install\" in each dir by entering \"npm install\", respectively.</li> <li>Configuration of backend: add \"loggers.json\", \"functionalAccounts.json\", \"proposalTypes.json\", \"datasetTypes.json\" und \".env\" files (there are examples named *.example).</li> <li>Start MongoDB: I do it using docker container. Recipe is get the image, e.g. bitnami/mongodb:latest, attach volume to it, e.g. \"mongodb\", mount it, e.g. to /bitnami/mongodb, port 27017. Open in host on 27017.</li> <li>Optional</li> <li>Start backend: in dir of backend run \"npm run start\". After about 10s you should be able to view the APIs from \"localhost:3000/explorer\" in the browser.</li> <li> <p>Start frontend: in dir of frontend run \"npm run start\". After about 40s one should see under \"localhost:4200\" to SciCat frontend.</p> </li> <li> <p>Voraussetzungen: Adminrechte, Git, Docker, NodeJS (ich habe es jetzt mit v.20.18.2 laufen) inkl. npm (bei mir v10.8.2).</p> </li> <li>Wenn Frontend laufen soll: \u00dcber npm angular installieren via \"npm install -g @angular\".</li> <li>Front- und Backend Repositories von GitHub klonen.</li> <li>Jeweils im Verzeichnis von Backend und Frontend einmal \"npm install\" um die Dependencies zu installieren.</li> <li>Backendkonfiguration: Das Backend braucht f\u00fcnf zus\u00e4tzliche Dateien um richtig zu laufen: \"loggers.json\", \"functionalAccounts.json\", \"proposalTypes.json\", \"datasetTypes.json\" und \".env\". F\u00fcr alle davon ist eine Beispieldatei schon vorhanden (die .env.example ist allerdings Mist, ich habe mal meine momentane angeh\u00e4ngt mit der es l\u00e4uft).</li> <li>MongoDB starten: Mache ich \u00fcber einen Docker-Container. Rezept: Image bitnami/mongodb:latest, Volumen \"mongodb\" anlegen und im Container auf /bitnami/mongodb mounten, Port 27017 im Container auf 27017 im Host \u00f6ffnen.</li> <li>(Optional?) MongoDB anlegen: \u00dcber Docker in den laufenden mongodb Container einloggen. Auf der Shell \"mongosh dacat\" ausf\u00fchren, das legt die DB \"dacat\" an (andere name geht auch, dann muss das nur auch in der .env anders!). Laut der alten Dokumentation muss man dann in der mongosh den Befehl \"db.Dataset.createIndex( { \"$**\" : \"text\" } )\" ausf\u00fchren, um Textindexing zu bekommen. Nicht 100% sicher ob das noch aktuell ist, musst du mal Max zu fragen.</li> <li>Backend starten: Im Backendverzeichnis \"npm run start\", sollte dann nach ca. 10s laufen. Testen, indem \"localhost:3000/explorer\" im Browser ge\u00f6ffnet wird - wenn Swagger zu sehen ist, l\u00e4uft es.</li> <li>Frontend starten: Nachdem das Backend l\u00e4uft, wieder \"npm run start\" im Frontendverzeichnis ausf\u00fchren. Frontend sollte nach Kompilierung (ca. 30s) auf \"localhost:4200\" zu sehen sein.</li> </ol>"},{"location":"operator-guide/","title":"Welcome to SciCat Operator's Guide","text":""},{"location":"operator-guide/#overview","title":"Overview","text":"<p>Getting SciCat up and running at your site should be rather straight forward for a test deployment. However turning into a production ready system may involve a bit more work, because different existing systems will need to be interfaced to SciCat.</p> <p>We highlight the core systems, backend and frontend, its features, configurations, and what else one could do to use exploit all of SciCat's capabilities.</p>"},{"location":"operator-guide/#features","title":"Features","text":"<p>SciCat promises to cover these core aspects in a flexible way:</p> <ol> <li>Searchable metadata fields, most common and highly specific ones. Thereby, SciCat can answer the needs of several, not all, photon and neutron sources. Since the needs may differ many great features are configurable.</li> <li>Provision of unique persistent identifiers not only for the internal catalogue, but also for to the global DOI system through e.g. ready pathway to publication via DataCite. </li> </ol>"},{"location":"operator-guide/#up-to-date-operators-information","title":"Up-to-date operator's information","text":"<p>Generally, the scicatlive documentation contains an up-to-date information how to set up and run the system <code>SciCat</code> interfacing it with various external, site-specific services. For troublshooting issues, please refer the User's Guide.</p>"},{"location":"operator-guide/#backend","title":"Backend","text":"<p>At the heart of the SciCat architecture there is the REST API server. This is a NodeJS application that uses the nestjs framework to generate RESTful APIs from JSON files that define these models Users, Datasets, Instruments, Proposals and Instruments. Following the Swagger/OpenAPI format SDKs can be generated in almost any language. You can explore the backend APIs directly via the Swagger interface.</p> <p>The persistence layer behind this API server is a MongoDB instance, i.e an open source, NoSQL, document-based database solution. The API server handles all the bi-directional communication from the REST interface to the database.</p> <p>These two components together comprise the \"backend\" of the architecture.</p>"},{"location":"operator-guide/#configuration-of-the-backend","title":"Configuration of the backend","text":"<p>There is one central place where one has a handle on how the backend is configured in SciCat: the dotenv file.</p>"},{"location":"operator-guide/#example-how-to-integrate-to-oidc-using-keycloak","title":"Example: How to integrate to OIDC using keycloak","text":"<p>Integration with an identity provider, Keycloak, can be done using Open ID Connect, a protocol for authentication. See scicatlive manual for more information on integration setup in SciCat backend.</p>"},{"location":"operator-guide/#frontend","title":"Frontend","text":"<p>To the REST server an arbitrary number of \"clients\" (frontends) can be connected. One of the most important clients is the web based GUI frontend. This allows to communicate with the data catalog in a user friendly way. It is based on the Angular (9+) technology and uses ngrx to communicate with the SciCat API and provide a searchable interface for datasets, as well as the option to carry out actions (i.e. archiving).</p> <p>In addition to the GUI other clients exist, such as command line (CLI) clients (example exist written in GO and Python) or desktop based GUI applications based on Qt. The CLI tools are especially useful for automated workflows, e.g. to get the data into the data catalog. This process is termed \"ingestion\" of the data. But they can also be used to add the data manually, especially for derived data, since this part of the workflow is often not possible to automate, in particular in truly experimental setups.</p>"},{"location":"operator-guide/#configuration-of-the-frontend","title":"Configuration of the frontend","text":"<p>To start a local instance of the frontend follow the recipe: install requirements, esp. angular, git clone the code, go the the directory and run \"npm run start\". Then you can launch it by entering \"localhost:4200\".</p>"},{"location":"operator-guide/#how-to-include-site-specific-logos","title":"How to include site-specific logos","text":"<p>See here for example procedure how to include your logo.</p>"},{"location":"operator-guide/#messaging-infractructure","title":"Messaging infractructure","text":"<p>SciCat strength is to intergrate into almost any existing infrastructure because messaging systems can be easily interfaced to SciCat that take over the communication to other services and systems.</p> <p>In particular RabbitMQ (used at PSI) and Apache Kafka are in use. Such systems can e.g. be used to interface to an tape archive system. To add the specific business logic you can e.g. add your own scripting layer. At PSI however a Node-RED based solution proved to be a stable and flexible platform for this purpose. Node-RED is a A NodeJS based visual programming tool to handle flows of data from one source to another. The following shows the Nod-RED flow used for communicating job requests to the PSI archive system.</p> <p></p>"},{"location":"operator-guide/#different-entry-points-to-scicat","title":"Different entry points to SciCat","text":"<p>One can ususally see SciCat datasets that is the metadata of data taken. It will be possible to sort according to samples, proposals, instruments and published data. Integration and generalisation of these entry points to the catalogue is currently in development. Another strength of SciCat is that it provides a publishing server.</p>"},{"location":"operator-guide/#publishing-server","title":"Publishing Server","text":"<p>In order to publish data you need to run a landing page server and you need to assign DOIs to your published data. Since the API server may be operated in an intranet, with no access to the internet the following architecture was chosen at PSI:</p> <p>An OAI-PMH server is running in a DMZ connected to a local Mongo instance. At publication time the data from SciCat is pushed to the external OAI-PMH server. From this server the landing page server can fetch the information about the published data. Also external DOI systems connect to this OAI-PMH server to synchronize the data with the world wide DOI system.</p> <p>If a user wants to download the full datasets of the published data, the data is copied from the internal file server to a https file server (acting as a cache file server) , which subsequently allows anonymous download of the data.</p>"},{"location":"operator-guide/#underlying-infrastructure-of-scicat-as-a-service","title":"Underlying Infrastructure of SciCat as a Service","text":"<p>You may or may not run the infrastructure as part of a Kubernetes cluster. E.g. at PSI the API server, the GUI application, RabbitMQ and the Node-RED instances are all deployed to a Kubernetes cluster, whereas the Mongo DB ist kept outside Kubernetes. Kubernetes is not necessary to have, but can simplify operations. Likewise \"helm charts\" or similar tools for managing software applications as a service. </p>"},{"location":"operator-guide/#who-uses-scicat","title":"Who uses SciCat?","text":"<p>Traditionally there were PSI, ESS and MaxIV that developed and deploy SciCat. More institutions joined the efforts and have pushed its development and many deploy photon and neutron labs in Europe and world-wide, see our project's for all facilities, contributors and users of SciCat.</p> <p>Below is a list of their documentation with more details on their deployment.</p> <ul> <li>ESS - European Spallation Source</li> <li>PSI - Paul-Scherrer-Institute</li> <li>MAXIV </li> <li>RFI</li> <li>ALS </li> <li>SOLEIL</li> <li>DESY</li> </ul>"},{"location":"proposals/","title":"Proposals","text":""},{"location":"proposals/#proposals","title":"Proposals","text":"<p>Here shall be a description of all meta data fields describing the proposal and how they are or can be related to datasets and samples.</p>"},{"location":"samples/","title":"Samples","text":""},{"location":"samples/#samples","title":"Samples","text":"<p>A dscription of which meta data fields can be expected in SciCats sample description will follow.</p>"},{"location":"sites/DESY/","title":"SciCat at DESY","text":"<p>Here we plan to provide more details on how SciCat is set up and used at DESY that might be beneficial for other institutions. For now we link to DESY's (internal) IT documentation on SciCat.</p>"},{"location":"sites/PSI/","title":"SciCat at PSI","text":"<p>SciCat empowers PSI to XYZ and is integrated to other technologies and systems:</p> <p></p>"},{"location":"swagger/","title":"Swagger - explore the Backend API","text":"<p>If SciCat has been set up and runs, one has direct access to the backend through the APIs via the Swagger tool or Explorer interface. Often, you can simply extend the <code>url</code> by <code>/explorer</code>, e.g. <code>https://myscicat.mydomain.de/explorer</code>. You will see a list of all APIs of that instance.</p> <p></p> <p>Once authenticated you can start using the endpoints.</p>"},{"location":"swagger/#authentication","title":"Authentication","text":"<p>You need to authenticate twice: 1. Get the SciCat token from the user setting when logged into SciCat via the main GUI. Copy paste it into the field \"Authorize\" in the explorer on the top right.   2. Login on the explorer page again with the same credentials. </p>"},{"location":"troubleshoot/","title":"Trouble shooting","text":"<p>When using SciCat it is possible you encounter unexpected things. Here is a list of what we had.</p>"},{"location":"troubleshoot/#1-no-images-visible","title":"#1 No images visible","text":"<p>Despite a working set up, sometimes no images are visible. The GUI may look like that: </p> <p>This may to be related to the site-specific setup. Check with your site-administrator or  github issues. Indeed there was a bug in the release, a new version fixed it.</p>"},{"location":"troubleshoot/#2-adminingestor-login-behaved-differently","title":"#2 Admin/Ingestor login behaved differently","text":"<p>Cause emails in functionalAccounts.json can not be twice the same.</p> <p><code>db.getCollection(\"User\").drop():</code></p> <p>delete User table </p> <p>fix by deleting the dublicate and relaunch backend at restart. </p>"},{"location":"troubleshoot/#3-scicat-complains-about-non-standard-pid","title":"#3 SciCat complains about non-standard PID","text":"<p>error message when trying an ingest of a dataset:</p> <p><code>Datasets\": [], \"usedSoftware\": [], \"relationships\": []} Scicat returned 400 Bad Request: PID is not following required standards {'message': 'PID is not following required standards', 'error': 'Bad Request', 'statusCode': 400}</code></p> <p>Fix was in the variable : <code>DATASET_CREATION_VALIDATION_REGEX</code> if enabled with default values. Switch is <code>DATASET_CREATION_VALIDATION_ENABLED</code>, see documentation of backend here.</p>"},{"location":"user-guide/","title":"Welcome to SciCat Users Guide","text":"<p>This is a short guide to most common questions users of SciCat can face.  First of all: What is SciCat? And what are its features, how can I use it? </p> <p>SciCat, a science catalogue, should serve you to find back your data through its metadata. Genrally all datasets in SciCat are a priori datasets of metadata. In a further step, SciCat can handle access to the actual the experimental data. </p> <p>SciCat is a bookkeeping tool accompanying some critical steps during the entire data life cycle which are: getting an overview of datasets for data analysis, for re-analysis, for publishing datasets, and in particular for publication. </p> <p>SciCat has several strong points:</p> <ul> <li>It can be integrated to almost any other service that has REST APIs. Therefore, site-specific applications can be easily integrated. </li> <li>The Data Model of SciCat forsees a schemaless fields for quite different use cases. This concept has been implemented for the main class, Datasets, but is extended to function in the same way for the other classes e.g. Proposlas, Samples, Intstruments and Published Data.</li> <li>Its components are based on OpenSource software projects and state of the art technologies. </li> </ul> <p>In the past 5 years SciCat has undergone major improvments in key areas for better user experience and re-structuring to meet the various different needs of photon science labs. The collaboration has grown and governance will be soon established.</p>"},{"location":"user-guide/#how-to-run-scicat","title":"How to run SciCat","text":"<p>More detailed information on how to run scicat, see scicatlive documentation. For more details on how to ingest, setup and deploy information from SciCat, see the site admin manual. </p>"},{"location":"user-guide/#how-to-use-scicat","title":"How to use SciCat","text":"<p>Once metadata is ingested into SciCat, the user can login and view, edit the metadata. There are four main classes which determine the functionality of SciCat: </p> <ol> <li>Datasets: Metadata in SciCat is therefore ideally sorted according to a dataset. It can have several associated files to which have the same metadata like thumbnail or e.g. tif files.</li> <li>Proposals: are used to link datasets to the proposal under which beamtime was granted.</li> <li>Instruments: Due to the nature of neutron science instruments can mean something different for photon scientists meaning. Here, if wanted, SciCat offers to add clear descriptions of your instruments used.</li> <li>Samples: SciCat offeres here the option to related its datasets with the physical sample or just related to other more sophisticated sample databases to track sample information, state, including storage location, characteristics and associated research data.</li> </ol> <p>For many the SciCat datasets are the entry point to the catalogue, but soon it will be possible to start with samples or published data records (registered metadata sets). You can just browse what's in the catalogue for any published datasets. Else one can list all datasets that I either own or have access to. Here is how to find more on how to proceed:</p>"},{"location":"user-guide/#how-tos-for-users-quick-links","title":"How-Tos for Users (Quick-links)","text":"<ul> <li>Login</li> <li>Search and find your data, see Datasets How to query</li> <li>How to change some fields after ingestion</li> <li>How to view history of changes to a dataset</li> <li>How to group and tag datasets.</li> <li>How to group and tag grouped datasets</li> </ul>"},{"location":"user-guide/#a-few-more-how-tos-for-users-and-site-admins","title":"A few more How-To's for users and site-admins","text":"<ul> <li>Where to find the version of the deployed SciCat Frontend? Check here.</li> </ul>"}]}