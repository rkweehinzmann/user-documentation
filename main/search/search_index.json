{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to SciCat Documenation","text":"<p>Find SciCat USERS Guide or SciCat Operator's Guide. Developers can read long the <code>READMEs</code> in github of the projects page and in both guides as well.</p>"},{"location":"doisIntro/","title":"Publishing SciCat datasets","text":"<p>A Digital Object Identifier (DOI) is issued to uniquely identify some object, e.g. data, used for reference e.g. in journal publications. In SciCat, if one selects his datasets, puts them into the cart and clicks <code>publish</code>, DOI minting process is triggered. This process compises the following steps:</p> <ol> <li>It defines a set of datasets to be published</li> <li>It assigns metadata relevant to the publication of the datasets, such as author, abstract etc</li> <li>It assigns a digital object identifier  DOI to the published data, which can e.g. be used to link from a journal article to the data</li> <li>It makes the data publicly available by providing a landing page that describes the data.</li> <li>It publishes the DOI to the worldwide DOI system , e.g. from Datacite</li> </ol> <p>So the first step is to select the datasets to be published</p> <p></p> <p>Put them into the cart by hitting the \"Add to Cart\" button. This step can be repeated to add further datasets. Once the selection is finished you open the cart (click on the cart symbol) to see the selected datasets:</p> <p></p> <p>Here you can still change your selection, remove datasets etc. Once this is finished simply hit the publish button. This leads you to the following screen:</p> <p></p> <p>Some of these fields will be pre-filled with information derived from the proposal data, such as the abstract. Independent of the pre-filling you can change the contents as you like until you are satisfied. Then hit the publish button, which leads you to the resulting display page:</p> <p></p> <p>Initially the status field is in state \"pending\". This means, the published data information has been stored, but not yet made public to the worldwide DOI system, and no landing page has been created yet. This gives the possibility, that (potentially another person) can have  a look at the data and do further editing by hitting the Edit button:</p> <p></p> <p>Once this is finished one can hit the \"register\" button (not shown in previous screenshot, because already in state registered)to register the DOI and thus making the data public. The resulting public landing page for this data then looks somethink like this</p> <p></p> <p>Finally you can have a look at all the published data by going to the Published Data menu item (again by clicking the user icon at the top right corner and choosing \"Published Data\"):</p> <p></p>"},{"location":"proposals/","title":"Proposals","text":""},{"location":"proposals/#proposals","title":"Proposals","text":"<p>Here shall be a description of all meta data fields describing the proposal and how they are or can be related to datasets and samples.</p>"},{"location":"samples/","title":"Samples","text":""},{"location":"samples/#samples","title":"Samples","text":"<p>A dscription of which meta data fields can be expected in SciCats sample description will follow.</p>"},{"location":"about/","title":"About the team - who are we?","text":"<p>SciCat has been initially developed at PSI but is now in production use across many other European and transatlantic countries. The core institutes are still PSI and ESS, but invaluable contribution comes from other labs, see SciCat Team for up-to-date details.</p>"},{"location":"about/#about-scicat-version","title":"About SciCat version","text":"<p>Here is where you find the frontend version.</p>"},{"location":"about/operatorHowTos/","title":"Where is the version of SciCat Frontend?","text":"<p>Version information under <code>user</code> </p>"},{"location":"backendconfig/","title":"Central Configuration of Backend: <code>.env</code>","text":"<p>The configuration file <code>.env</code> allows the systems administrator to configure connected services, like authentication services and message queues, and also switching on/off almost all available features and is read by the backend at runtime.</p> <p>There are currently many configurable additions to SciCat which makes it very flexible these are:</p> <ul> <li>OIDC for authenticatoin</li> <li>LDAP for authentication</li> <li>Elastic Search</li> <li>SMTP for sending emails to notify users of SciCat jobs</li> <li>AMQP to provide a message queue for the jobs</li> </ul>"},{"location":"backendconfig/#environment-variables","title":"Environment Variables","text":"<p>All environment variables can be used in the <code>.env</code> filee. The current source code contains an example .env file, named .env.example, listing all (79) environment variables available to configure the backend. They can be found here and define</p> <ul> <li>How SciCat handles access rights and connects to identity providers - such as LDAP or OIDC</li> <li>How to configure DOIs.</li> <li>How to configure elasitc search (ES)</li> <li>How to configure jobs</li> </ul> <p>The list is compiled according to the configuration class defined in src/config/configuration.ts.</p> <ul> <li> <p>ADMIN_GROUPS:   list of groups that have admin priviliges default: \"\" format: comma separated list of strings. Leading and trailing spaces are trimmed.  </p> </li> <li> <p>DELETE_GROUPS:   list of groups that are allowed to delete content default: \"\" format: comma separated list of strings. Leading and trailing spaces are trimmed.  </p> </li> <li> <p>CREATE_DATASET_GROUPS:   list of non admin groups that are allowed to create datasets without pid. The pid is assigned by the system. If set to \"#all\", all users can create a dataset belonging to any of the groups they belong to.   default: \"#all\" format: comma separated list of strings. Leading and trailing spaces are trimmed.  </p> </li> <li> <p>CREATE_DATASET_WITH_PID_GROUPS:   list of non admin groups that are allowed to create datasets with explicit pid. If set to \"#all\", all users can create a dataset belonging to any of the groups they belong to and with esplicit pid.   If the pid verification is enabled, pid will be validated agains the specification passed. default: \"\" format: comma separated list of strings. Leading and trailing spaces are trimmed.  </p> </li> <li> <p>CREATE_DATASET_PRIVILEGED_GROUPS:   list of non admin groups that are allowed to create datasets for groups they do not belong to. If set to \"#all\", all users can create a dataset belonging to any group with explicit pid.   If the pid verification is enabled, pid will be validated agains the specification passed. default: \"\" format: comma separated list of strings. Leading and trailing spaces are trimmed.  </p> </li> <li> <p>PROPOSAL_GROUPS:   list of non admin groups that are allowed to create and update proposals for groups they do not belong to. If set to \"#all\", all users can create a dataset belonging to any group with explicit pid. default: \"\" format: comma separated list of strings. Leading and trailing spaces are trimmed  </p> </li> <li> <p>SAMPLE_GROUPS:   list of non admin groups that are allowed to create and update samples for the groups they belong to. If set to \"#all\", all users can create a dataset belonging to their group. default: \"\" format: comma separated list of strings. Leading and trailing spaces are trimmed  </p> </li> <li> <p>SAMPLE_PRIVILEGED_GROUPS:   list of non admin groups that are allowed to create samples for any groups, but can only update samples belonging to groups they belong to.   default: \"\" format: comma separated list of strings. Leading and trailing spaces are trimmed  </p> </li> <li> <p>ACCESS_GROUPS_STATIC_VALUES:   List of groups assigned by default to all users. Used in the vanilla implementation for easy configuration.   If you do not want or need to assign any default group, it should be set to empty string \"\".   Default value: \"\" format: Comman separated list of strings. Leading and trailing spaces are trimmed example: \"group1,group2,group3,...\"  </p> </li> <li> <p>ACCESS_GROUP_SERVICE_TOKEN:   Access token needed to access the API specified in ACCESS_GROUP_SERVICE_API_URL, used to retrieve access groups from a third party system.   _format*: string </p> </li> <li> <p>ACCESS_GROUP_SERVICE_API_URL:   Well formed url of the service API used to provide access groups. Only one value is allowed. format: string example: \"https://my.access.group/service/api/url\"</p> </li> <li> <p>DOI_PREFIX:   The facility DOI prefix, with trailing slash. default: \"\" format: string  </p> </li> <li> <p>EXPRESS_SESSION_SECRET:   Secret used to set up express session. default: \"\" format: string  </p> </li> <li> <p>LOGOUT_URL:   URL specified upon successful logout. It is returned in the json object for the frontend, or third party UI, to be used locally. default: \"\" format: string  </p> </li> <li> <p>HTTP_MAX_REDIRECTS:   Max number of redirects for http requests. default: 5 format: integer  </p> </li> <li> <p>HTTP_TIMEOUT:   Timeout from http requests in ms. default: 5000 format: integer</p> </li> <li> <p>JWT_SECRET:   The secret used to create any JWT token, used for authorization. default: \"\" format: string  </p> </li> <li> <p>JWT_EXPIRES_IN:   Expiration time of any JWT token in seconds. default: 3600 (s) format: integer  </p> </li> <li> <p>JWT_NEVER_EXPIRES:   Length of time that the never expiring jwt token will last. default: 100y format: string as in number of years  </p> </li> <li> <p>LDAP_URL:   Full URI (including port) of your local LDAP server, if this is your selected authentication method. default: No default example: ldaps://ldap.server.com:636/  format: string  </p> </li> <li> <p>LDAP_BIND_DN:   Bind DN to access information on your LDAP server. default: No default format: string  </p> </li> <li> <p>LDAP_BIND_CREDENTIALS:   Credentials associated with your bind DN to acccess your LDAP server. default: No default format: string  </p> </li> <li> <p>LDAP_SEARCH_BASE:   Search base for your LDAP server. default: No default  format: string  </p> </li> <li> <p>LDAP_SEARCH_FILTER:   Search filter for you LDAP server. default: No default format: string  example: \"(LDAPUsername={{username}})\"  </p> </li> <li> <p>LDAP_MODE:   type of ldap server we are communicating with NEEDS TO BE UPDATED. Not sure which other values are accepted default: ad format: string acceptable values: ad  </p> </li> <li> <p>LDAP_EXTERNAL_ID:   LDAP matching field that provides the external id default: sAMAccountName format: string  </p> </li> <li> <p>LDAP_USERNAME:   LDAP field providing the username default: displayName format: string  </p> </li> <li> <p>OIDC_ISSUER:   Full URL of your OIDC identity provider default: No default format: string example: \"https://identity.your.facility/your/realm\"  </p> </li> <li> <p>OIDC_CLIENT_ID:   Client id used to convert OIDC code to OIDC token. This is assigned in the OIDC service when the token is generated default: No default format: string example: \"scicat\"  </p> </li> <li> <p>OIDC_CLIENT_SECRET:    Token used to convert OIDC code to OIDC token. This is assigned in the OIDC service when the token is generated example: \"90f1268...\"  </p> </li> <li> <p>OIDC_CALLBACK_URL:   URL of the endpoint that is called when the authentication has been executed with the OIDC service.  default: No default  format: string   example: \"http://localhost:3000/api/v3/oidc/callback\"  </p> </li> <li> <p>OIDC_SCOPE:   Information returned by the OIDC service together with token default: No default format: string  example: \"openid profile email\"  </p> </li> <li> <p>OIDC_SUCCESS_URL:   Frontend URL that the user is directed to after a successful authentication. It must be a valid frontend URL. default: No default format: string example: \"http://localhost:3000/Datasets\"  </p> </li> <li> <p>OIDC_ACCESS_GROUPS:   field used to retrieve access groups from the OIDC service. It is not used in the vanilla implementation. default: No default format: string example: \"access_groups\"  </p> </li> <li> <p>OIDC_ACCESS_GROUPS_PROPERTY:   name of the OIDC property used to retrieve the users groups from OIDC. default: none format: string  </p> </li> <li> <p>OIDC_AUTO_LOGOUT:   if enabled, when login out from SciCat, we logout from OIDC also. default: false format: boolean  </p> </li> <li> <p>OIDC_RETURN_URL:   URL the user is redirected after a successful logout default: none format: string  </p> </li> <li> <p>LOGBOOK_ENABLED:   Flag to enable/disable the Logbook endpoints.   accept values: \"yes\", \"no\" default: no  format: string  </p> </li> <li> <p>LOGBOOK_BASE_URL:   The base URL to the SciChat wrapper API. Only required if Logbook is enabled. default: \"http://localhost:3030/scichatapi\" format: string  </p> </li> <li> <p>LOGBOOK_USERNAME:   The username used to authenticate to the SciChat wrapper API. Only required if Logbook is enabled. default: No default format: string  </p> </li> <li> <p>LOGBOOK_PASSWORD:   The password used to authenticate to the SciChat wrapper API. Only required if Logbook is enabled. default: No default format: string  </p> </li> <li> <p>METADATA_KEYS_RETURN_LIMIT:   The maximum number of keys returned by the <code>/Datasets/metadataKeys</code> endpoint. default: No default format: integer  </p> </li> <li> <p>METADATA_PARENT_INSTANCES_RETURN_LIMIT:   The maximum number of Datasets used to extract metadata keys in the <code>/Datasets/metadataKeys</code> endpoint. default: No default format: integer  </p> </li> <li> <p>MONGODB_URI:   The URI for your MongoDB instance. default: No default format: string \"mongodb://:@:27017/\"   <li> <p>OAI_PROVIDER_ROUTE:   URI to OAI provider, which is used in the <code>/publisheddata/:id/resync</code> endpoint. default: no default format: string  </p> </li> <li> <p>PID_PREFIX:   The facility PID prefix, with trailing slash. default: no default format: string  </p> </li> <li> <p>PUBLIC_URL_PREFIX:   The base URL to the facility Landing Page. default: No default format: string example: \"https://doi.ess.eu/detail/\"  </p> </li> <li> <p>PORT:   The port on which the backend listen on. default: 3000 format: integer  </p> </li> <li> <p>RABBITMQ_ENABLED:   Flag to enable/disable RabbitMQ consumer.   accepted values: \"yes\", \"no\" deprecated. Will be removed in future releases. default: no format: string  </p> </li> <li> <p>RABBITMQ_HOSTNAME:   The hostname of the RabbitMQ message broker. Only required if RabbitMQ is enabled. deprecated. Will be removed in future releases. default: no default default: string  </p> </li> <li> <p>RABBITMQ_USERNAME:   The username used to authenticate to the RabbitMQ message broker. Only required if RabbitMQ is enabled. deprecated. Will be removed in future releases. default: no default format: string  </p> </li> <li> <p>RABBITMQ_PASSWORD:   The password used to authenticate to the RabbitMQ message broker. Only required if RabbitMQ is   enabled. deprecated. Will be removed in future releases. default: no default format: string  </p> </li> <li> <p>REGISTER_DOI_URI:   URI to the organization that registers the facilities DOIs. default: no default format: string example: \"https://mds.test.datacite.org/doi\"  </p> </li> <li> <p>REGISTER_METADATA_URI:   URI to the organization that registers the facilities published data metadata. default: no default format: string example: =\"https://mds.test.datacite.org/metadata\"  </p> </li> <li> <p>DOI_USERNAME:   Username used to authenticate on the DOI site default: no default format: string  </p> </li> <li> <p>DOI_PASSWORD:   Password used to authenticate on the DOI site default: no default format: string  </p> </li> <li> <p>SITE:   The name of your site. default: no default format: string  </p> </li> <li> <p>SMTP_HOST:   Host of SMTP server. deprecated. Will be removed in future releases. default: no default format: string  </p> </li> <li> <p>SMTP_MESSAGE_FROM:   Email address that emails should be sent from. deprecated. Will be removed in future releases. default: no default format: string, email  </p> </li> <li> <p>SMTP_PORT:   Port of SMTP server. deprecated. Will be removed in future releases. default: no default format: string  </p> </li> <li> <p>SMTP_SECURE:   Secure of SMTP server. deprecated. Will be removed in future releases. default: no default format: string  </p> </li> <li> <p>POLICY_PUBLICATION_SHIFT:   Number of years that needs to elapse before the dataset is made publicly acceessible default: 3 format: integer  </p> </li> <li> <p>POLICY_RETENTION_SHIFT:   Number of years that the datasets are kept online before are archived or deleted. A negative value means that they are never archived/deleted default: -1 format: integer  </p> </li> <li> <p>ELASTICSEARCH_ENABLED:   Flag to enable/disable the ElasticSearch service   accept values: \"yes\", \"no\" default: no default format: string  </p> </li> <li> <p>ES_HOST:   The base URL to the Elasticsearch cluster. Use <code>http</code> if xpack.security is disabled default: no default format: string  example: \"https://localhost:9200\" or \"http://localhost:9200\"  </p> </li> <li> <p>MONGODB_COLLECTION:   Collection name to be mapped into specified Elasticsearch index default: no default format: string  </p> </li> <li> <p>ES_MAX_RESULT:    Maximum records can be indexed into Elasticsearch. default: 10000 format: number  </p> </li> <li> <p>ES_FIELDS_LIMIT:    The total number of fields in an index. default: 1000 format: number  </p> </li> <li> <p>ES_INDEX:   The total number of fields in an index. default: no default format: string  </p> </li> <li> <p>ES_REFRESH:   The total number of fields in an index.   accept values: true, false, \"wait_for\" default: false format: boolean or string  </p> </li> <li> <p>ES_USERNAME:   Elasticsearch cluster username. default: no default, optional. format: string  </p> </li> <li> <p>ELASTIC_PASSWORD:    Elasticsearch cluster password. default: no default. format: string  </p> </li>"},{"location":"backendconfig/#environment-variables-as-now","title":"Environment Variables as now","text":"<pre><code>ACCESS_GROUP_SERVICE_API_URL=\"\"\nACCESS_GROUP_SERVICE_TOKEN=\"\"\nDOI_PREFIX=\"&lt;DOI_PREFIX&gt;\"\nEXPRESS_SESSION_SECRET=\"&lt;EXPRESS_SESSION_SECRET&gt;\"\nHTTP_MAX_REDIRECTS=5\nHTTP_TIMEOUT=5000\nJWT_SECRET=&lt;JWT_SECRET&gt;\nJWT_EXPIRES_IN=3600\nLDAP_URL=\"ldaps://ldap.server.com:636/\"\nLDAP_BIND_DN=\"&lt;USERNAME&gt;@server.com\"\nLDAP_BIND_CREDENTIALS=&lt;PASSWORD&gt;\nLDAP_SEARCH_BASE=&lt;SEARCH_BASE&gt;\nLDAP_SEARCH_FILTER=\"(LDAPUsername={{username}})\"\nLOGBOOK_ENABLED=\"no\"\nLOGBOOK_BASE_URL=\"http://localhost:3030/scichatapi\"\n\nMETADATA_KEYS_RETURN_LIMIT=100\nMETADATA_PARENT_INSTANCES_RETURN_LIMIT=100\nMONGODB_URI=\"mongodb://&lt;USERNAME&gt;:&lt;PASSWORD&gt;@&lt;HOST&gt;:27017/&lt;DB_NAME&gt;\"\nOAI_PROVIDER_ROUTE=\"&lt;OAI_PROVIDER_ROUTE&gt;\"\nPID_PREFIX=\"&lt;PID_PREFIX&gt;\"\nPUBLIC_URL_PREFIX=\"https://doi.esss.se/detail/\"\nPORT=3000\nRABBITMQ_ENABLED=&lt;\"yes\"|\"no\"&gt;\nRABBITMQ_HOSTNAME=\"localhost\"\nRABBITMQ_USERNAME=\"rabbitmq\"\nRABBITMQ_PASSWORD=\"rabbitmq\"\nREGISTER_DOI_URI=\"https://mds.test.datacite.org/doi\"\nREGISTER_METADATA_URI=\"https://mds.test.datacite.org/metadata\"\nDOI_USERNAME=\"username\"\nDOI_PASSWORD=\"password\"\nSITE=&lt;SITE&gt;\nEMAIL_TYPE=&lt;\"smtp\"|\"ms365\"&gt;\nEMAIL_FROM=&lt;MESSAGE_FROM&gt;\nSMTP_HOST=&lt;SMTP_HOST&gt;\nSMTP_PORT=&lt;SMTP_PORT&gt;\nSMTP_SECURE=&lt;\"yes\"|\"no\"&gt;\nMS365_TENANT_ID=&lt;tenantId&gt;\nMS365_CLIENT_ID=&lt;clientId&gt;\nMS365_CLIENT_SECRET=&lt;clientSecret&gt;\n\nDATASET_CREATION_VALIDATION_ENABLED=true\nDATASET_CREATION_VALIDATION_REGEX=\"^[0-9A-F]{8}-[0-9A-F]{4}-4[0-9A-F]{3}-[89AB][0-9A-F]{3}-[0-9A-F]{12}$\"\n\nADMIN_GROUPS=\"\"\nDELETE_GROUPS=\"\"\nCREATE_DATASET_GROUPS=\"all\"\nCREATE_DATASET_WITH_PID_GROUPS=\"\"\nCREATE_DATASET_PRIVILEGED_GROUPS=\"\"\nCREATE_JOB_GROUPS=\"\"\nUPDATE_JOB_GROUPS=\"\"\nSAMPLE_PRIVILEGED_GROUPS=\"sampleingestor\"\nSAMPLE_GROUPS=\"group1\"\nPROPOSAL_GROUPS=\"\"\n\nACCESS_GROUPS_GRAPHQL_ENABLED=true\nACCESS_GROUP_SERVICE_TOKEN=\"\"\nACCESS_GROUP_SERVICE_API_URL=\"\"\nACCESS_GROUP_SERVICE_HANDLER=\"\"\nACCESS_GROUPS_STATIC_ENABLED=true\nACCESS_GROUPS_OIDCPAYLOAD_ENABLED=true\n\nOIDC_USERINFO_MAPPING_FIELD_USERNAME=\"iss, sub\"\nOIDC_USERINFO_MAPPING_FIELD_DISPLAYNAME=\"preferred_username\"\nOIDC_USERINFO_MAPPING_FIELD_EMAIL=\"email\"\nOIDC_USERINFO_MAPPING_FIELD_GROUP=\"groups\"\nOIDC_USERQUERY_OPERATOR=&lt;\"or\"|\"and\"&gt;\nOIDC_USERQUERY_FILTER=\"username:username, email:email\"\n\nELASTICSEARCH_ENABLED=&lt;\"yes\"|\"no\"&gt;\nSTACK_VERSION=\"8.8.2\"\nCLUSTER_NAME=\"es-cluster\"\nMEM_LIMIT=\"4G\"\nMONGODB_COLLECTION=\"Dataset\"\nES_MAX_RESULT=100000\nES_FIELDS_LIMIT=400000\nES_INDEX=\"dataset\"\nES_PORT=9200\nES_HOST=\"https://localhost:9200\"\nES_USERNAME=\"elastic\"\nES_PASSWORD=\"duo-password\"\nES_REFRESH=&lt;\"wait_for\"|\"false\"&gt;\n\nLOGGERS_CONFIG_FILE=\"loggers.json\"\nDATASET_TYPES_FILE=\"datasetTypes.json\"\nPROPOSAL_TYPES_FILE=\"proposalTypes.json\"\n</code></pre>"},{"location":"backendconfig/#how-to-configure-ldap","title":"How to configure LDAP","text":"<p>Here are some details that are currently unknown to the author.</p>"},{"location":"backendconfig/#how-to-configure-oidc","title":"How to configure OIDC","text":"<p>Here are some details that are currently unknown to the author.</p>"},{"location":"backendconfig/#how-to-configure-doi-minting","title":"How to configure DOI minting","text":"<p>In SciCat one can publish selected datasets that triggers a DOI minting process. Find here a short introduction and instructions how to set up such a service. SciCat also has the option to make datasets publicly available, if you wish to do that follow this Link</p>"},{"location":"backendconfig/#more-advanced-options","title":"More advanced options","text":"<p>If you are compiling the application from source, you can edit the file src/config/configuration.ts with the correct values for your infrastructure. This option is still undocumented, although it is our intention to provide a detailed how-to guide as soon as we can.</p>"},{"location":"backendconfig/dois/","title":"DOI minting in SciCat - How to publish datasets","text":""},{"location":"backendconfig/dois/#introduction","title":"Introduction","text":"<p>User introduction can be found here.</p>"},{"location":"datasets/","title":"Datasets","text":"<p>Datasets can include several files which e.g. comprise a self-contained measurement - which is fully customizeable during ingestion of meta data. Users can search, view, list the meta data of a dataset. </p> <p>To group and tag datasets is depicted here. Datasets can also be issued to be published: either removing the restricted view or triggering the process of obtaining a DOI for the selected datasets, see old description.</p>"},{"location":"datasets/#how-to-query-datasets","title":"How to query datasets","text":""},{"location":"datasets/#dataset-file-listing","title":"Dataset file listing","text":"<p>Here is the view of files belonging to a dataset: Below the PID on the top, one finds the tab Datafiles: </p>"},{"location":"datasets/#dataset-attachments","title":"Dataset attachments","text":"<p>What kind of attachement can be saved? Will they be searchable? Can also other formats be attached than pngs?</p> <p>On the dataset details page, you can click on the Attachments tab </p> <p>Simply follow the instructions to upload an image. The size is restricted to be below 16 MB.</p>"},{"location":"datasets/#view-raw-json-data","title":"View raw JSON data","text":"<p>Scientific meta data is shown in JSON under its section and looks like this: </p>"},{"location":"datasets/#get-raw-json-data","title":"Get raw JSON data","text":"<p>One can also get the JSON file via the swagger API. If set up, one can directly access the API endpoints of SciCat backend. Usually the address is in the form: <code>my-scicat-instance.country/explorer</code>, swagger is accessible via the explorer. One needs to authenticate by copying the token from the GUI into the field authorize, then find the dataset of interest, by trying it out it will display you dataset and you can download it in JSON format.</p>"},{"location":"datasets/#edit-scientific-meta-data","title":"Edit Scientific meta data","text":"<p>// WARNING: this is the old text!  If enabled, fields in the scientific metadata can be modified and edited by the owner of the data by hitting the \"Edit\" Icon. The user can add,remove or change metadata fields, every change will create a new record in the databse with it's history.</p> <p></p>"},{"location":"datasets/#new-developments-on-dataset-types","title":"New developments on dataset types","text":"<p>Generalize datatypes to remove restrictions of <code>raw</code> and <code>derived</code> types (difference was a set of dataset properties).</p> <p>datasetTypes</p>"},{"location":"datasets/Publishing/","title":"Publishing datasets","text":"<p>There are two ways of publishing datasets in SciCat, one via the \"publish button\" for each dataset, and secondly when adding to it to a selection of datasets for which a DOI is registered.</p>"},{"location":"datasets/Publishing/#publish-without-doi-registration","title":"Publish without DOI registration","text":"<p>Using the \"publish button\" allows for making a dataset visible within the catalogue for a non-authenticated user. Each dataset has this button on the top right.   </p>"},{"location":"datasets/Publishing/#publish-with-doi-registeration","title":"Publish with DOI registeration","text":"<p>The user can select one or several datasets for DOI (Digital Object Identifier) registration which means that a record in DataCite, a DOI provider, will be made that points to a DESY landing page. SciCat offers a DataCite conform schema during the workflow. Any data that is known to the data catalog can be published. The publication workflow does the following:</p> <ol> <li>The logged in user can define a set of datasets to be published.</li> <li>That person assigns metadata relevant to the publication of the datasets, such as title, author (currently the name(s) under 'Creator'), abstract etc. One can work on it at a later stage, too and re-edit the registration. Note, that editing will be allowed once the registration request has been sent.</li> <li>A DOI is assigned to the published data which can e.g. be used to link from a journal article to the data.</li> <li>It makes the data publicly available by providing a landing page that describes the data.</li> <li>It publishes the DOI to the worldwide DOI system , e.g. from Datacite</li> </ol> <p>So the first step is to select the datasets that should be published:</p> <p></p> <p>Then by hitting the \"Add to Cart\" button these datasets are available in the Cart. This step can be repeated to add further datasets. Once the selection is finished you open the Cart ( click on the Cart symbol and choose actions ) to see the selected datasets:</p> <p></p> <p>Here you can still change your selection, remove datasets etc. Once this is finished simply hit the publish button. This leads you to the following screen:</p> <p></p> <p>Some of these fields will be pre-filled with information derived from the proposal data, such as the abstract. Independent of the pre-filling you can change the contents as you like until you are satisfied. Then hit the publish button, which leads you to the resulting display page:</p> <p></p> <p>Initially the status field is in state \"pending\". This means, the published data information has been stored, but not yet made public to the worldwide DOI system, and no landing page has been created yet. This gives the possibility, that (potentially another person) can have  a look at the data and do further editing by hitting the Edit button:</p> <p></p> <p>Once this is finished one can hit the \"register\" button (not shown in previous screenshot, because already in state registered)to register the DOI and thus making the data public. The resulting public landing page for this data then looks somethink like this</p> <p></p> <p>Finally you can have a look at all the published data by going to the Published Data menu item (again by clicking the user icon at the top right corner and choosing \"Published Data\"):</p> <p></p> <p>This short video demonstrates how you can add an attachment to your dataset and publish the data.</p>"},{"location":"datasets/datasetTypes/","title":"Datasets Types","text":"<p>A new feature was introduced: instead of only providing <code>raw</code> and <code>derived</code> custom dataset types are now available, e.g. for the proposed dataset collections (hierarchical grouping). Control of which types are allowed should be on the site administration side and be configurable, see also PR. </p>"},{"location":"datasets/datasetTypes/#how-is-this-new-dataset-type-used","title":"How is this new dataset type used?","text":"<p>Add any type into a separate JSON named <code>datasetTypes.json</code>.</p>"},{"location":"datasets/datasetTypes/#changes-made","title":"Changes made","text":"<ul> <li>configuration: add new datasetTypes field and support to read in a json file for custom datasest types (either by env variable or default location \"datasetTypes.json\")</li> <li>add support for custom dataset types in dataset schema</li> <li>dataset controller: update endpoints and validation methods to accept custom dataset types.</li> </ul>"},{"location":"datasets/datasetTypes/#examples-of-usage","title":"Examples of usage","text":"<p>Abstract layer of dataset types, e.g. type <code>collection</code> defined with more, other or less properties or information per dataset. Can be tailored to site-specific adoptions.</p>"},{"location":"datasets/grouping_tagging_ds/","title":"Grouping datasets","text":"<p>An easy way of quickly grouping some of the datasets is the option to tag each dataset individually and then search by this tag. In the General Information of the dataset one can EDIT it by adding a new KEYWORD (note Keywords are not case sensitive). Saving this keyword enables a search on them at a later point. </p> <p>Here one sees the EDIT button (bottom right). </p> <p>// erscheint noch nicht mittig... Having added your keywords you can use them to search:  {align=center}</p> <p>On the left you see the filters of your datasets, all results with e.g. \"myowntagtest\". </p>"},{"location":"login/","title":"Login","text":"<p>To get access to all the data, for which you have read access, you first have to login. Otherwise you can browse only public datasets, see anonymous browsing.</p> <p>To login hit the \"Sign in\" Icon at the top right corner.</p> <p></p> <p>There are two types of account associated with the DataCatalog: Functional and User. A functional account will primarily be used by software and system administrators to deal with backups and other tasks.</p> <p>User accounts are tied into the login system that is used by your institution, for example: Active Directory. You are able to log in to the system using the same credentials you use on that account. This process is called authenitication in IT tech terminology</p> <p>When you login as a user your user management system will assign groups to the logged in user. Each dataset is also assigned to one such group (via the so called ownerGroup field), and you can view the datasets only, if you are member of the corresponding group. The logic that defines, what parts of the data you can see, is called \"authorization\" in IT terminology. The first page you'll see after login is the \"Dashboard\".</p> <p>Another  example login page from PSI is here</p> <p></p>"},{"location":"login/Anonymous/","title":"Anonymous View","text":"<p>As soon as you visit the starting page of the GUI application, and you are not yet logged in, you will see a list of datasets, which have been published, and can therefore be looked at anonymously:</p> <p>You can filter the datasets by choosing the \"facets\" on the left navigation section (e.g. in the screenshot for the location field a value of \"V20\" was selected).</p> <p></p> <p>From this list you can choose a particular dataset to see the details of this dataset</p> <p></p>"},{"location":"login/Dashboard/","title":"Dashboard","text":""},{"location":"login/Dashboard/#dashboard","title":"Dashboard","text":"<p>The dashboard is the first page that you see after being logged in. It contains an overview of all datasets that you have access to.</p> <p></p>"},{"location":"login/Dashboard/#menu-access-to-different-information-pages","title":"Menu access to different information pages","text":"<p>You can always navigate to other parts of the application, simply by clicking on the user icon on the top right corner </p> <p></p>"},{"location":"login/Dashboard/#filtering-datasets","title":"Filtering Datasets","text":"<p>You can currently filter across 5 different fields: 1. Location (= field creationLocation) 2. Groups (= field ownerGroup) 3. Type (=field type - e.g. raw data or derived data ) 4. Keywords  =field keywords, the tags added to the datasets) 5. Start - End Date ( = field createdAt, show datasets captured between the dates that you have set)</p> <p>The text fields provide an auto completion, which becomes visible as you type. </p> <p>One click on the date calendar selects the start date and a second selects the end date. Make sure you select 2 dates.</p> <p>In the following screenshot the datasets are filterd by the condition ownerGroup=\"p17301\"</p> <p></p>"},{"location":"login/Dashboard/#searching","title":"Searching","text":"<p>The text field at the top of the navigation bar allows you to search the metadata for any word contained in the metadata (but not arbitrary substrings). The search starts automatically when to start to type in this textfield, so better type fast ;-) </p>"},{"location":"login/Dashboard/#configure-table-columns","title":"Configure table columns","text":"<p>The cog wheel symbol on the top right allows to define the columns, that you want to see in the table</p>"},{"location":"login/Dashboard/#view-details","title":"View Details","text":"<p>To view a dataset simply click on it in the table and a more detailed view will load (this is covered in the next section)</p>"},{"location":"operator/","title":"Welcome to SciCat Manual for Admins","text":"<p>This is a short guide containing most of how SciCat can be operated. Many technical aspects are already described in the scicatlive documentation.</p> <p>We highlight in more detail aspects for someone exploring core SciCat software. </p> <ul> <li>How to set up development versions of the new version of dataset endpoints.</li> <li>How to configure SciCat to mint DOIs.</li> <li>How to integrate SciCat with other systems.</li> </ul>"},{"location":"operator/datasetsv4/","title":"How to run new dataset endpoint in v4","text":"<p>For now one can run and play with the new version of dataset endpoints v4. Here is how to set it up:</p> <ol> <li>Pre-requisits: admin rights, git, docker, nodejs (v.20.18.2) and npm (v10.8.2).</li> <li>For frontend to run, install angular like this: \"npm install -g @angular\"</li> <li>Git clone frontend and backend repository.</li> <li>Launch \"npm install\" in each dir by entering \"npm install\", respectively.</li> <li>Configuration of backend: add \"loggers.json\", \"functionalAccounts.json\", \"proposalTypes.json\", \"datasetTypes.json\" und \".env\" files (there are examples named *.example).</li> <li>Start MongoDB: I do it using docker container. Recipe is get the image, e.g. bitnami/mongodb:latest, attach volume to it, e.g. \"mongodb\", mount it, e.g. to /bitnami/mongodb, port 27017. Open in host on 27017.</li> <li>Optional</li> <li>Start backend: in dir of backend run \"npm run start\". After about 10s you should be able to view the APIs from \"localhost:3000/explorer\" in the browser.</li> <li> <p>Start frontend: in dir of frontend run \"npm run start\". After about 40s one should see under \"localhost:4200\" to SciCat frontend.</p> </li> <li> <p>Voraussetzungen: Adminrechte, Git, Docker, NodeJS (ich habe es jetzt mit v.20.18.2 laufen) inkl. npm (bei mir v10.8.2).</p> </li> <li>Wenn Frontend laufen soll: \u00dcber npm angular installieren via \"npm install -g @angular\".</li> <li>Front- und Backend Repositories von GitHub klonen.</li> <li>Jeweils im Verzeichnis von Backend und Frontend einmal \"npm install\" um die Dependencies zu installieren.</li> <li>Backendkonfiguration: Das Backend braucht f\u00fcnf zus\u00e4tzliche Dateien um richtig zu laufen: \"loggers.json\", \"functionalAccounts.json\", \"proposalTypes.json\", \"datasetTypes.json\" und \".env\". F\u00fcr alle davon ist eine Beispieldatei schon vorhanden (die .env.example ist allerdings Mist, ich habe mal meine momentane angeh\u00e4ngt mit der es l\u00e4uft).</li> <li>MongoDB starten: Mache ich \u00fcber einen Docker-Container. Rezept: Image bitnami/mongodb:latest, Volumen \"mongodb\" anlegen und im Container auf /bitnami/mongodb mounten, Port 27017 im Container auf 27017 im Host \u00f6ffnen.</li> <li>(Optional?) MongoDB anlegen: \u00dcber Docker in den laufenden mongodb Container einloggen. Auf der Shell \"mongosh dacat\" ausf\u00fchren, das legt die DB \"dacat\" an (andere name geht auch, dann muss das nur auch in der .env anders!). Laut der alten Dokumentation muss man dann in der mongosh den Befehl \"db.Dataset.createIndex( { \"$**\" : \"text\" } )\" ausf\u00fchren, um Textindexing zu bekommen. Nicht 100% sicher ob das noch aktuell ist, musst du mal Max zu fragen.</li> <li>Backend starten: Im Backendverzeichnis \"npm run start\", sollte dann nach ca. 10s laufen. Testen, indem \"localhost:3000/explorer\" im Browser ge\u00f6ffnet wird - wenn Swagger zu sehen ist, l\u00e4uft es.</li> <li>Frontend starten: Nachdem das Backend l\u00e4uft, wieder \"npm run start\" im Frontendverzeichnis ausf\u00fchren. Frontend sollte nach Kompilierung (ca. 30s) auf \"localhost:4200\" zu sehen sein.</li> </ol>"},{"location":"operator-manual/","title":"Welcome to SciCat Operator's Manual","text":"<p>General manual for site-administrators can be found in the scicatlive documentation, it contains information how to set up and run a SciCat instance. For troublshooting issues, please see the User's Guide.</p>"},{"location":"operator-manual/#configuration-of-the-backend","title":"Configuration of the Backend","text":"<p>There is one central place where one has a handle on how the Backend is configured in SciCat: the dotenv file.</p>"},{"location":"operator-manual/#hands-on-scicat","title":"Hands-on SciCat","text":"<p>For getting familiar with SciCat's APIs, you can explore via the Swagger interface.</p>"},{"location":"operator-manual/#configuration-of-the-frontend","title":"Configuration of the Frontend","text":"<p>Here we link to site-specific set ups. </p>"},{"location":"operator-manual/#links-to-site-specific-scicat-documentation-of-user-sites","title":"Links to site-specific SciCat documentation of user sites","text":"<ul> <li>ESS</li> <li>PSI</li> <li>MAXIV</li> <li>SOLEIL</li> <li>DESY</li> </ul>"},{"location":"sites/DESY/","title":"SciCat at DESY","text":"<p>Here we plan to describe how SciCat is set up and used at DESY. DESY has a proposal system called <code>DOOR</code>, more than 20 beamlines at PETRA and also laser beam experiments at FLASH.</p> <p>Setup: 1. Structure of SciCats dataset are used</p> <p>Usage:</p>"},{"location":"sites/PSI/","title":"SciCat at PSI","text":"<p>SciCat empowers PSI to XYZ and is integrated to other technologies and systems:</p> <p></p>"},{"location":"swagger/","title":"Swagger or Explorer - The Backend API","text":"<p>If SciCat has been set up and runs, one has direct access to the backend through the APIs via the Swagger tool or Explorer interface. Often, you can simply extend the <code>url</code> by <code>/explorer</code>, e.g. <code>https://myscicat.mydomain.de/explorer</code>. You will see a list of all APIs of that instance.</p> <p></p> <p>Once authenticated you can start using the endpoints.</p>"},{"location":"swagger/#authentication","title":"Authentication","text":"<p>You need to authenticate twice: 1. Get the SciCat token from the user setting when logged into SciCat via the main GUI. Copy paste it into the field \"Authorize\" in the explorer on the top right.   2. Login on the explorer page again with the same credentials. </p>"},{"location":"troubleshoot/","title":"Trouble shooting","text":"<p>When using SciCat it is possible you encounter unexpected things. Here is a list of what we had.</p>"},{"location":"troubleshoot/#1-no-images-visible","title":"#1 No images visible","text":"<p>Despite a working set up, sometimes no images are visible. The GUI may look like that: </p> <p>This may to be related to the site-specific setup. Check with your site-administrator or  github issues. Indeed there was a bug in the release, a new version fixed it.</p>"},{"location":"troubleshoot/#2-adminingestor-login-behaved-differently","title":"#2 Admin/Ingestor login behaved differently","text":"<p>Cause emails in functionalAccounts.json can not be twice the same.</p> <p><code>db.getCollection(\"User\").drop():</code></p> <p>delete User table </p> <p>fix by deleting the dublicate and relaunch backend at restart. </p>"},{"location":"troubleshoot/#3-scicat-complains-about-non-standard-pid","title":"#3 SciCat complains about non-standard PID","text":"<p>error message when trying an ingest of a dataset:</p> <p><code>Datasets\": [], \"usedSoftware\": [], \"relationships\": []} Scicat returned 400 Bad Request: PID is not following required standards {'message': 'PID is not following required standards', 'error': 'Bad Request', 'statusCode': 400}</code></p> <p>Fix was in the variable : <code>DATASET_CREATION_VALIDATION_REGEX</code> if enabled with default values. Switch is <code>DATASET_CREATION_VALIDATION_ENABLED</code>, see documentation of backend here.</p>"},{"location":"user-manual/","title":"Welcome to SciCat Users Manual","text":"<p>This is a short guide to most common questions users of SciCat can face. First of all: What is SciCat? And why should I use it? SciCat, a science catalogue, should serve you to find back your data. SciCat is a bookkeeping tool accompanying some critical steps during the entire data life cycle which are: getting an overview of datasets for data analysis, for re-analysis, for publishing datasets, and in particular for publication. In SciCat, only the meta data is stored, descriptions to identify a certain measurements.</p> <p>We highlight most promiment features that SciCat offers, but note that SciCat is a general software layer which when integrated with site-specific application develops its full potential. For more detailed information on how to run scicat, see scicatlive documentation. For more details on how to ingest, setup and deploy information from SciCat, see the site admin manual. </p>"},{"location":"user-manual/#features-quick-links-to-how-tos-for-users","title":"Features: Quick links to How-To's for users","text":"<p>Your data may be of type raw or derived, you may want to login or just browse what's in the catalogue. Here is how to find more on how to proceed:</p> <ul> <li>Login</li> <li>Search and find your data, see Datasets How to query</li> <li>How to change some fields after ingestion</li> <li>How to view history of changes to a dataset</li> <li>How to group and tag datasets.</li> <li>How to group and tag grouped datasets</li> </ul>"},{"location":"user-manual/#a-few-more-how-tos-for-users-and-site-admins","title":"A few more How-To's for users and site-admins","text":"<ul> <li>Where to find the version of the deployed SciCat Frontend? Check here.</li> </ul>"},{"location":"user-manual/#structure-of-scicat","title":"Structure of SciCat","text":"<p>These main classes determine the functionality of SciCat: </p> <ol> <li>Datasets: This class is the most elaborated one. </li> <li>Proposals: are used to link datasets to the proposal under which beamtime was granted.</li> <li>Instruments: Depending on the science background <code>instruments</code> can mean something different.</li> <li>Samples: </li> </ol>"}]}